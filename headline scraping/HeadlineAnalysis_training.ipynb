{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Statement Author</th>\n",
       "      <th>Statement</th>\n",
       "      <th>Rating</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>statement_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>unique_words</th>\n",
       "      <th>lexical_richness</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>noun_%</th>\n",
       "      <th>pronoun_%</th>\n",
       "      <th>verb_%</th>\n",
       "      <th>adj_%</th>\n",
       "      <th>determiner_%</th>\n",
       "      <th>foreign_%</th>\n",
       "      <th>cleaned_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Fentrice Driskell</td>\n",
       "      <td>\"$1 of every $3 (Ron DeSantis) spends comes fr...</td>\n",
       "      <td>true</td>\n",
       "      <td>every ron desantis spends come federal government</td>\n",
       "      <td>73</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>10.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['every', 'ron', 'desantis', 'spends', 'come',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Robert Ortt</td>\n",
       "      <td>If New York’s proposed limits on natural gas i...</td>\n",
       "      <td>true</td>\n",
       "      <td>new york proposed limit natural gas building t...</td>\n",
       "      <td>127</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>123.48</td>\n",
       "      <td>2</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['new', 'york', 'proposed', 'limit', 'natural'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Tony Evers</td>\n",
       "      <td>“Wisconsin is the nation’s top cranberry produ...</td>\n",
       "      <td>true</td>\n",
       "      <td>wisconsin nation top cranberry producer fact f...</td>\n",
       "      <td>122</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>101.08</td>\n",
       "      <td>2</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['wisconsin', 'nation', 'top', 'cranberry', 'p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Morgan Luttrell</td>\n",
       "      <td>\"Biden drained America's Strategic Petroleum R...</td>\n",
       "      <td>true</td>\n",
       "      <td>biden drained america strategic petroleum rese...</td>\n",
       "      <td>86</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>12.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['biden', 'drained', 'america', 'strategic', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Melissa Agard</td>\n",
       "      <td>\"Historically, our spring elections (including...</td>\n",
       "      <td>true</td>\n",
       "      <td>historically spring election including state s...</td>\n",
       "      <td>117</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>16.00</td>\n",
       "      <td>6</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['historically', 'spring', 'election', 'includ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>1135</td>\n",
       "      <td>TikTok posts</td>\n",
       "      <td>“As of today, no one has the right to film or ...</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>today one right film photograph mr biden climb...</td>\n",
       "      <td>138</td>\n",
       "      <td>91</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>102.06</td>\n",
       "      <td>6</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['today', 'one', 'right', 'film', 'photograph'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>1136</td>\n",
       "      <td>Facebook posts</td>\n",
       "      <td>\"mRNA is not a vaccine\" — it's \"actually an op...</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>mrna vaccine actually operating system run bil...</td>\n",
       "      <td>105</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>112.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['mrna', 'vaccine', 'actually', 'operating', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>1137</td>\n",
       "      <td>Facebook posts</td>\n",
       "      <td>Video says COVID-19 vaccines are “weapons of m...</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>video say covid vaccine weapon mass destructio...</td>\n",
       "      <td>100</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>17.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['video', 'say', 'covid', 'vaccine', 'weapon',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>1138</td>\n",
       "      <td>Facebook posts</td>\n",
       "      <td>Says Ben Shapiro said on Twitter that his “red...</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>say ben shapiro said twitter red pill moment s...</td>\n",
       "      <td>96</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>17.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['say', 'ben', 'shapiro', 'said', 'twitter', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>1139</td>\n",
       "      <td>Facebook posts</td>\n",
       "      <td>Nostradamus predicted that a “feeble man” woul...</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>nostradamus predicted feeble man would rule we...</td>\n",
       "      <td>98</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>80.92</td>\n",
       "      <td>1</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['nostradamus', 'predicted', 'feeble', 'man', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1140 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0   Statement Author  \\\n",
       "0              0  Fentrice Driskell   \n",
       "1              1        Robert Ortt   \n",
       "2              2         Tony Evers   \n",
       "3              3    Morgan Luttrell   \n",
       "4              4      Melissa Agard   \n",
       "...          ...                ...   \n",
       "1135        1135       TikTok posts   \n",
       "1136        1136     Facebook posts   \n",
       "1137        1137     Facebook posts   \n",
       "1138        1138     Facebook posts   \n",
       "1139        1139     Facebook posts   \n",
       "\n",
       "                                              Statement      Rating  \\\n",
       "0     \"$1 of every $3 (Ron DeSantis) spends comes fr...        true   \n",
       "1     If New York’s proposed limits on natural gas i...        true   \n",
       "2     “Wisconsin is the nation’s top cranberry produ...        true   \n",
       "3     \"Biden drained America's Strategic Petroleum R...        true   \n",
       "4     \"Historically, our spring elections (including...        true   \n",
       "...                                                 ...         ...   \n",
       "1135  “As of today, no one has the right to film or ...  pants-fire   \n",
       "1136  \"mRNA is not a vaccine\" — it's \"actually an op...  pants-fire   \n",
       "1137  Video says COVID-19 vaccines are “weapons of m...  pants-fire   \n",
       "1138  Says Ben Shapiro said on Twitter that his “red...  pants-fire   \n",
       "1139  Nostradamus predicted that a “feeble man” woul...  pants-fire   \n",
       "\n",
       "                                                cleaned  statement_length  \\\n",
       "0     every ron desantis spends come federal government                73   \n",
       "1     new york proposed limit natural gas building t...               127   \n",
       "2     wisconsin nation top cranberry producer fact f...               122   \n",
       "3     biden drained america strategic petroleum rese...                86   \n",
       "4     historically spring election including state s...               117   \n",
       "...                                                 ...               ...   \n",
       "1135  today one right film photograph mr biden climb...               138   \n",
       "1136  mrna vaccine actually operating system run bil...               105   \n",
       "1137  video say covid vaccine weapon mass destructio...               100   \n",
       "1138  say ben shapiro said twitter red pill moment s...                96   \n",
       "1139  nostradamus predicted feeble man would rule we...                98   \n",
       "\n",
       "      word_count  sentence_count  unique_words  lexical_richness  \\\n",
       "0             49               1            12             10.00   \n",
       "1             98               1            19            123.48   \n",
       "2             87               1            18            101.08   \n",
       "3             68               1            12             12.00   \n",
       "4             85               1            16             16.00   \n",
       "...          ...             ...           ...               ...   \n",
       "1135          91               3            22            102.06   \n",
       "1136          66               1            19            112.00   \n",
       "1137          69               1            16             17.00   \n",
       "1138          69               1            17             17.00   \n",
       "1139          69               1            14             80.92   \n",
       "\n",
       "      punctuation_count    noun_%  pronoun_%    verb_%     adj_%  \\\n",
       "0                     7  0.157895   0.000000  0.000000  0.052632   \n",
       "1                     2  0.407407   0.000000  0.185185  0.111111   \n",
       "2                     2  0.428571   0.035714  0.071429  0.071429   \n",
       "3                     4  0.312500   0.000000  0.062500  0.000000   \n",
       "4                     6  0.272727   0.090909  0.136364  0.000000   \n",
       "...                 ...       ...        ...       ...       ...   \n",
       "1135                  6  0.454545   0.030303  0.030303  0.000000   \n",
       "1136                  7  0.307692   0.038462  0.038462  0.000000   \n",
       "1137                  2  0.380952   0.000000  0.142857  0.095238   \n",
       "1138                  1  0.450000   0.050000  0.200000  0.050000   \n",
       "1139                  1  0.521739   0.000000  0.086957  0.043478   \n",
       "\n",
       "      determiner_%  foreign_%  \\\n",
       "0         0.105263        0.0   \n",
       "1         0.074074        0.0   \n",
       "2         0.071429        0.0   \n",
       "3         0.062500        0.0   \n",
       "4         0.045455        0.0   \n",
       "...            ...        ...   \n",
       "1135      0.090909        0.0   \n",
       "1136      0.076923        0.0   \n",
       "1137      0.047619        0.0   \n",
       "1138      0.000000        0.0   \n",
       "1139      0.130435        0.0   \n",
       "\n",
       "                                      cleaned_tokenized  \n",
       "0     ['every', 'ron', 'desantis', 'spends', 'come',...  \n",
       "1     ['new', 'york', 'proposed', 'limit', 'natural'...  \n",
       "2     ['wisconsin', 'nation', 'top', 'cranberry', 'p...  \n",
       "3     ['biden', 'drained', 'america', 'strategic', '...  \n",
       "4     ['historically', 'spring', 'election', 'includ...  \n",
       "...                                                 ...  \n",
       "1135  ['today', 'one', 'right', 'film', 'photograph'...  \n",
       "1136  ['mrna', 'vaccine', 'actually', 'operating', '...  \n",
       "1137  ['video', 'say', 'covid', 'vaccine', 'weapon',...  \n",
       "1138  ['say', 'ben', 'shapiro', 'said', 'twitter', '...  \n",
       "1139  ['nostradamus', 'predicted', 'feeble', 'man', ...  \n",
       "\n",
       "[1140 rows x 18 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('PolitifactDatasetFeatures.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import nltk.stem as ns\n",
    "import string\n",
    "import re\n",
    "\n",
    "ps = ns.PorterStemmer()\n",
    "lemma = ns.WordNetLemmatizer()\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "def remove_punctuation(x):\n",
    "    punctuation = string.punctuation\n",
    "    no_punct = \"\".join([word for word in x if word not in punctuation])\n",
    "    return no_punct\n",
    "\n",
    "def remove_stopwords(x):\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    no_sw = [word for word in x if word not in stopwords]\n",
    "    return no_sw\n",
    "\n",
    "#function built to use either stemming or lematization\n",
    "def lemmatize(x):\n",
    "    lemmatized = [lemma.lemmatize(word) for word in x]\n",
    "    return lemmatized\n",
    "\n",
    "\n",
    "#all of those functions inside one function to keep code clean\n",
    "def clean_data(x):\n",
    "    #tokens = re.sub(\"[^a-zA-Z]\", \" \", x.lower())\n",
    "    essay_v = re.sub(\"[^a-zA-Z]\", \" \", x)\n",
    "    tokens = essay_v.lower().split()\n",
    "    no_sw = remove_stopwords(tokens)\n",
    "    root = lemmatize(no_sw)\n",
    "    cleaned = ' '.join(root)\n",
    "    return cleaned\n",
    "\n",
    "def clean_tokenize(x):\n",
    "    #tokens = re.sub(\"[^a-zA-Z]\", \" \", x.lower())\n",
    "    essay_v = re.sub(\"[^a-zA-Z]\", \" \", x)\n",
    "    tokens = essay_v.lower().split()\n",
    "    no_sw = remove_stopwords(tokens)\n",
    "    root = lemmatize(no_sw)\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer=clean_tokenize)\n",
    "feat_df = df[['Statement Author','statement_length', 'word_count', 'sentence_count', 'unique_words', 'lexical_richness', 'punctuation_count', 'noun_%', 'pronoun_%', 'verb_%', 'adj_%', 'determiner_%', 'foreign_%']]\n",
    "X = pd.concat([pd.DataFrame(vectorizer.fit_transform(df['Statement']).toarray()), feat_df], axis = 1)\n",
    "y = df['Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>unique_words</th>\n",
       "      <th>lexical_richness</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>noun_%</th>\n",
       "      <th>pronoun_%</th>\n",
       "      <th>verb_%</th>\n",
       "      <th>adj_%</th>\n",
       "      <th>determiner_%</th>\n",
       "      <th>foreign_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>10.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>123.48</td>\n",
       "      <td>2</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>101.08</td>\n",
       "      <td>2</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>12.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>16.00</td>\n",
       "      <td>6</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>102.06</td>\n",
       "      <td>6</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>112.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>17.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>17.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>80.92</td>\n",
       "      <td>1</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1140 rows × 3563 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6    7    8    9  ...  sentence_count  \\\n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...               1   \n",
       "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...               1   \n",
       "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...               1   \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...               1   \n",
       "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...               1   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...             ...   \n",
       "1135  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...               3   \n",
       "1136  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...               1   \n",
       "1137  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...               1   \n",
       "1138  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...               1   \n",
       "1139  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...               1   \n",
       "\n",
       "      unique_words  lexical_richness  punctuation_count    noun_%  pronoun_%  \\\n",
       "0               12             10.00                  7  0.157895   0.000000   \n",
       "1               19            123.48                  2  0.407407   0.000000   \n",
       "2               18            101.08                  2  0.428571   0.035714   \n",
       "3               12             12.00                  4  0.312500   0.000000   \n",
       "4               16             16.00                  6  0.272727   0.090909   \n",
       "...            ...               ...                ...       ...        ...   \n",
       "1135            22            102.06                  6  0.454545   0.030303   \n",
       "1136            19            112.00                  7  0.307692   0.038462   \n",
       "1137            16             17.00                  2  0.380952   0.000000   \n",
       "1138            17             17.00                  1  0.450000   0.050000   \n",
       "1139            14             80.92                  1  0.521739   0.000000   \n",
       "\n",
       "        verb_%     adj_%  determiner_%  foreign_%  \n",
       "0     0.000000  0.052632      0.105263        0.0  \n",
       "1     0.185185  0.111111      0.074074        0.0  \n",
       "2     0.071429  0.071429      0.071429        0.0  \n",
       "3     0.062500  0.000000      0.062500        0.0  \n",
       "4     0.136364  0.000000      0.045455        0.0  \n",
       "...        ...       ...           ...        ...  \n",
       "1135  0.030303  0.000000      0.090909        0.0  \n",
       "1136  0.038462  0.000000      0.076923        0.0  \n",
       "1137  0.142857  0.095238      0.047619        0.0  \n",
       "1138  0.200000  0.050000      0.000000        0.0  \n",
       "1139  0.086957  0.043478      0.130435        0.0  \n",
       "\n",
       "[1140 rows x 3563 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             true\n",
       "1             true\n",
       "2             true\n",
       "3             true\n",
       "4             true\n",
       "           ...    \n",
       "1135    pants-fire\n",
       "1136    pants-fire\n",
       "1137    pants-fire\n",
       "1138    pants-fire\n",
       "1139    pants-fire\n",
       "Name: Rating, Length: 1140, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import joblib\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "num_cols = ['statement_length', 'word_count', 'sentence_count', 'unique_words', 'lexical_richness', 'punctuation_count']\n",
    "bin_cols = ['Statement Author']\n",
    "\n",
    "ct = ColumnTransformer([('standard_scaler', StandardScaler(), num_cols), \n",
    "                        ('label_encoder', OrdinalEncoder(), bin_cols)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carloalmeda/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, f1_score\n",
    "\n",
    "clfXGB = Pipeline(steps = [('XGBoost', XGBClassifier())])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('XGBoost',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, early_stopping_rounds=None,\n",
       "                               enable_categorical=False, eval_metric=None,\n",
       "                               feature_types=None, gamma=0, gpu_id=-1,\n",
       "                               grow_policy='depthwise', importance_type=None,\n",
       "                               interaction_constraints='',\n",
       "                               learning_rate=0.300000012, max_bin=256,\n",
       "                               max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "                               max_delta_step=0, max_depth=6, max_leaves=0,\n",
       "                               min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=100,\n",
       "                               n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
       "                               random_state=0, ...))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfXGB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found unknown categories ['Chad Mayes', 'Norm Eisen', 'Texas GOP', 'Gwen Graham', 'Kelly Alexander', 'Caleb Rowden', 'Silvestre Reyes', 'Eric Trump', 'Energy Transfer', 'Pearson Sharp', 'Desiree Rogers', 'Nick Freitas', 'Tammy Duckworth', 'David Menchetti', 'Rand Paul', 'Roger Stone', 'VoteVets.org', 'Keith Pekau', 'Jake Tapper', 'Ted Yoho', 'Lisa McClain', 'Robert F. Kennedy, Jr.', 'Ann Wagner', 'Rana Foroohar', 'Brian Tyler Cohen', 'John Chiang', 'Ted Nugent', 'Dennis Kucinich', 'Adam Putnam', 'National Republican Senatorial Committee', 'A Better Wisconsin Together', 'Kevin Nicholson', 'Mandy Cohen', 'Josh Hawley', 'Richard Cordray', 'Jeff Jackson', 'Van Wanggaard', 'Bob Good', 'Lauren Boebert', 'Joseph Crowley', 'Devin LeMahieu', 'Chris Kennedy', 'Monica Crowley', 'Troy LaRaviere', 'Ivanka Trump', 'The Coalition for Public Schools', 'Ron DeSantis', 'Illinois Policy Institute', 'Bono', 'Eric Holcomb', 'Emily Compagno', 'Jenny Wilson', 'Rachel Campos-Duffy', 'Darrell Steinberg', 'Michelle Obama', 'Joni Ernst', 'Ann Teich', 'Derrick Crowe', 'Allen Thomas', 'Patricia Pike', 'Jeff Brandes', 'Phil Scott'] in column 0 during transform",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2n/b06jflfn76z784mwwtws7gyr0000gp/T/ipykernel_2204/4006441693.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclfXGB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m         \u001b[0mscore_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    746\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m         Xs = self._fit_transform(\n\u001b[0m\u001b[1;32m    749\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m_fit_transform\u001b[0;34m(self, X, y, func, fitted, column_as_strings)\u001b[0m\n\u001b[1;32m    604\u001b[0m         )\n\u001b[1;32m    605\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m             return Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[1;32m    607\u001b[0m                 delayed(func)(\n\u001b[1;32m    608\u001b[0m                     \u001b[0mtransformer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrans\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfitted\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_transform_one\u001b[0;34m(transformer, X, y, weight, **fit_params)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_transform_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    877\u001b[0m     \u001b[0;31m# if we have a weight for this transformer, multiply output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0mTransformed\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m         \"\"\"\n\u001b[0;32m--> 930\u001b[0;31m         X_int, X_mask = self._transform(\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, X, handle_unknown, force_all_finite, warn_on_unknown)\u001b[0m\n\u001b[1;32m    140\u001b[0m                         \u001b[0;34m\" during transform\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                     )\n\u001b[0;32m--> 142\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mwarn_on_unknown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found unknown categories ['Chad Mayes', 'Norm Eisen', 'Texas GOP', 'Gwen Graham', 'Kelly Alexander', 'Caleb Rowden', 'Silvestre Reyes', 'Eric Trump', 'Energy Transfer', 'Pearson Sharp', 'Desiree Rogers', 'Nick Freitas', 'Tammy Duckworth', 'David Menchetti', 'Rand Paul', 'Roger Stone', 'VoteVets.org', 'Keith Pekau', 'Jake Tapper', 'Ted Yoho', 'Lisa McClain', 'Robert F. Kennedy, Jr.', 'Ann Wagner', 'Rana Foroohar', 'Brian Tyler Cohen', 'John Chiang', 'Ted Nugent', 'Dennis Kucinich', 'Adam Putnam', 'National Republican Senatorial Committee', 'A Better Wisconsin Together', 'Kevin Nicholson', 'Mandy Cohen', 'Josh Hawley', 'Richard Cordray', 'Jeff Jackson', 'Van Wanggaard', 'Bob Good', 'Lauren Boebert', 'Joseph Crowley', 'Devin LeMahieu', 'Chris Kennedy', 'Monica Crowley', 'Troy LaRaviere', 'Ivanka Trump', 'The Coalition for Public Schools', 'Ron DeSantis', 'Illinois Policy Institute', 'Bono', 'Eric Holcomb', 'Emily Compagno', 'Jenny Wilson', 'Rachel Campos-Duffy', 'Darrell Steinberg', 'Michelle Obama', 'Joni Ernst', 'Ann Teich', 'Derrick Crowe', 'Allen Thomas', 'Patricia Pike', 'Jeff Brandes', 'Phil Scott'] in column 0 during transform"
     ]
    }
   ],
   "source": [
    "clfXGB.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b6ec5c042ddf83e1a0c3f39fbc3e80edf14e579d2f804f9b839dc9985dcd105"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
