{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('PolitifactDatasetFeatures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Statement Author</th>\n",
       "      <th>Statement</th>\n",
       "      <th>Rating</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>statement_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>unique_words</th>\n",
       "      <th>...</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>noun_%</th>\n",
       "      <th>pronoun_%</th>\n",
       "      <th>verb_%</th>\n",
       "      <th>adj_%</th>\n",
       "      <th>determiner_%</th>\n",
       "      <th>foreign_%</th>\n",
       "      <th>cleaned_tokenized</th>\n",
       "      <th>emotion</th>\n",
       "      <th>profanity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fentrice Driskell</td>\n",
       "      <td>\"$1 of every $3 (Ron DeSantis) spends comes fr...</td>\n",
       "      <td>true</td>\n",
       "      <td>every ron desantis spends come federal government</td>\n",
       "      <td>73</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['every', 'ron', 'desantis', 'spends', 'come',...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>0.008152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Robert Ortt</td>\n",
       "      <td>If New York’s proposed limits on natural gas i...</td>\n",
       "      <td>true</td>\n",
       "      <td>new york proposed limit natural gas building t...</td>\n",
       "      <td>127</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['new', 'york', 'proposed', 'limit', 'natural'...</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>0.056929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Tony Evers</td>\n",
       "      <td>“Wisconsin is the nation’s top cranberry produ...</td>\n",
       "      <td>true</td>\n",
       "      <td>wisconsin nation top cranberry producer fact f...</td>\n",
       "      <td>122</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['wisconsin', 'nation', 'top', 'cranberry', 'p...</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>0.039250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Morgan Luttrell</td>\n",
       "      <td>\"Biden drained America's Strategic Petroleum R...</td>\n",
       "      <td>true</td>\n",
       "      <td>biden drained america strategic petroleum rese...</td>\n",
       "      <td>86</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['biden', 'drained', 'america', 'strategic', '...</td>\n",
       "      <td>Fear</td>\n",
       "      <td>0.030024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Melissa Agard</td>\n",
       "      <td>\"Historically, our spring elections (including...</td>\n",
       "      <td>true</td>\n",
       "      <td>historically spring election including state s...</td>\n",
       "      <td>117</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['historically', 'spring', 'election', 'includ...</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>0.008631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>1135</td>\n",
       "      <td>1135</td>\n",
       "      <td>TikTok posts</td>\n",
       "      <td>“As of today, no one has the right to film or ...</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>today one right film photograph mr biden climb...</td>\n",
       "      <td>138</td>\n",
       "      <td>91</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['today', 'one', 'right', 'film', 'photograph'...</td>\n",
       "      <td>Fear</td>\n",
       "      <td>0.121310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>1136</td>\n",
       "      <td>1136</td>\n",
       "      <td>Facebook posts</td>\n",
       "      <td>\"mRNA is not a vaccine\" — it's \"actually an op...</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>mrna vaccine actually operating system run bil...</td>\n",
       "      <td>105</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['mrna', 'vaccine', 'actually', 'operating', '...</td>\n",
       "      <td>Fear</td>\n",
       "      <td>0.049405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>1137</td>\n",
       "      <td>1137</td>\n",
       "      <td>Facebook posts</td>\n",
       "      <td>Video says COVID-19 vaccines are “weapons of m...</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>video say covid vaccine weapon mass destructio...</td>\n",
       "      <td>100</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['video', 'say', 'covid', 'vaccine', 'weapon',...</td>\n",
       "      <td>Fear</td>\n",
       "      <td>0.005492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>1138</td>\n",
       "      <td>1138</td>\n",
       "      <td>Facebook posts</td>\n",
       "      <td>Says Ben Shapiro said on Twitter that his “red...</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>say ben shapiro said twitter red pill moment s...</td>\n",
       "      <td>96</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['say', 'ben', 'shapiro', 'said', 'twitter', '...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>0.297600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>1139</td>\n",
       "      <td>1139</td>\n",
       "      <td>Facebook posts</td>\n",
       "      <td>Nostradamus predicted that a “feeble man” woul...</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>nostradamus predicted feeble man would rule we...</td>\n",
       "      <td>98</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['nostradamus', 'predicted', 'feeble', 'man', ...</td>\n",
       "      <td>Fear</td>\n",
       "      <td>0.074195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1140 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0.1  Unnamed: 0   Statement Author  \\\n",
       "0                0           0  Fentrice Driskell   \n",
       "1                1           1        Robert Ortt   \n",
       "2                2           2         Tony Evers   \n",
       "3                3           3    Morgan Luttrell   \n",
       "4                4           4      Melissa Agard   \n",
       "...            ...         ...                ...   \n",
       "1135          1135        1135       TikTok posts   \n",
       "1136          1136        1136     Facebook posts   \n",
       "1137          1137        1137     Facebook posts   \n",
       "1138          1138        1138     Facebook posts   \n",
       "1139          1139        1139     Facebook posts   \n",
       "\n",
       "                                              Statement      Rating  \\\n",
       "0     \"$1 of every $3 (Ron DeSantis) spends comes fr...        true   \n",
       "1     If New York’s proposed limits on natural gas i...        true   \n",
       "2     “Wisconsin is the nation’s top cranberry produ...        true   \n",
       "3     \"Biden drained America's Strategic Petroleum R...        true   \n",
       "4     \"Historically, our spring elections (including...        true   \n",
       "...                                                 ...         ...   \n",
       "1135  “As of today, no one has the right to film or ...  pants-fire   \n",
       "1136  \"mRNA is not a vaccine\" — it's \"actually an op...  pants-fire   \n",
       "1137  Video says COVID-19 vaccines are “weapons of m...  pants-fire   \n",
       "1138  Says Ben Shapiro said on Twitter that his “red...  pants-fire   \n",
       "1139  Nostradamus predicted that a “feeble man” woul...  pants-fire   \n",
       "\n",
       "                                                cleaned  statement_length  \\\n",
       "0     every ron desantis spends come federal government                73   \n",
       "1     new york proposed limit natural gas building t...               127   \n",
       "2     wisconsin nation top cranberry producer fact f...               122   \n",
       "3     biden drained america strategic petroleum rese...                86   \n",
       "4     historically spring election including state s...               117   \n",
       "...                                                 ...               ...   \n",
       "1135  today one right film photograph mr biden climb...               138   \n",
       "1136  mrna vaccine actually operating system run bil...               105   \n",
       "1137  video say covid vaccine weapon mass destructio...               100   \n",
       "1138  say ben shapiro said twitter red pill moment s...                96   \n",
       "1139  nostradamus predicted feeble man would rule we...                98   \n",
       "\n",
       "      word_count  sentence_count  unique_words  ...  punctuation_count  \\\n",
       "0             49               1            12  ...                  7   \n",
       "1             98               1            19  ...                  2   \n",
       "2             87               1            18  ...                  2   \n",
       "3             68               1            12  ...                  4   \n",
       "4             85               1            16  ...                  6   \n",
       "...          ...             ...           ...  ...                ...   \n",
       "1135          91               3            22  ...                  6   \n",
       "1136          66               1            19  ...                  7   \n",
       "1137          69               1            16  ...                  2   \n",
       "1138          69               1            17  ...                  1   \n",
       "1139          69               1            14  ...                  1   \n",
       "\n",
       "        noun_%  pronoun_%    verb_%     adj_%  determiner_%  foreign_%  \\\n",
       "0     0.157895   0.000000  0.000000  0.052632      0.105263        0.0   \n",
       "1     0.407407   0.000000  0.185185  0.111111      0.074074        0.0   \n",
       "2     0.428571   0.035714  0.071429  0.071429      0.071429        0.0   \n",
       "3     0.312500   0.000000  0.062500  0.000000      0.062500        0.0   \n",
       "4     0.272727   0.090909  0.136364  0.000000      0.045455        0.0   \n",
       "...        ...        ...       ...       ...           ...        ...   \n",
       "1135  0.454545   0.030303  0.030303  0.000000      0.090909        0.0   \n",
       "1136  0.307692   0.038462  0.038462  0.000000      0.076923        0.0   \n",
       "1137  0.380952   0.000000  0.142857  0.095238      0.047619        0.0   \n",
       "1138  0.450000   0.050000  0.200000  0.050000      0.000000        0.0   \n",
       "1139  0.521739   0.000000  0.086957  0.043478      0.130435        0.0   \n",
       "\n",
       "                                      cleaned_tokenized   emotion profanity  \n",
       "0     ['every', 'ron', 'desantis', 'spends', 'come',...     Happy  0.008152  \n",
       "1     ['new', 'york', 'proposed', 'limit', 'natural'...  Surprise  0.056929  \n",
       "2     ['wisconsin', 'nation', 'top', 'cranberry', 'p...  Surprise  0.039250  \n",
       "3     ['biden', 'drained', 'america', 'strategic', '...      Fear  0.030024  \n",
       "4     ['historically', 'spring', 'election', 'includ...  Surprise  0.008631  \n",
       "...                                                 ...       ...       ...  \n",
       "1135  ['today', 'one', 'right', 'film', 'photograph'...      Fear  0.121310  \n",
       "1136  ['mrna', 'vaccine', 'actually', 'operating', '...      Fear  0.049405  \n",
       "1137  ['video', 'say', 'covid', 'vaccine', 'weapon',...      Fear  0.005492  \n",
       "1138  ['say', 'ben', 'shapiro', 'said', 'twitter', '...     Happy  0.297600  \n",
       "1139  ['nostradamus', 'predicted', 'feeble', 'man', ...      Fear  0.074195  \n",
       "\n",
       "[1140 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import nltk.stem as ns\n",
    "import string\n",
    "import re\n",
    "\n",
    "ps = ns.PorterStemmer()\n",
    "lemma = ns.WordNetLemmatizer()\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "def remove_punctuation(x):\n",
    "    punctuation = string.punctuation\n",
    "    no_punct = \"\".join([word for word in x if word not in punctuation])\n",
    "    return no_punct\n",
    "\n",
    "def remove_stopwords(x):\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    no_sw = [word for word in x if word not in stopwords]\n",
    "    return no_sw\n",
    "\n",
    "#function built to use either stemming or lematization\n",
    "def lemmatize(x):\n",
    "    lemmatized = [lemma.lemmatize(word) for word in x]\n",
    "    return lemmatized\n",
    "\n",
    "\n",
    "#all of those functions inside one function to keep code clean\n",
    "def clean_data(x):\n",
    "    #tokens = re.sub(\"[^a-zA-Z]\", \" \", x.lower())\n",
    "    essay_v = re.sub(\"[^a-zA-Z]\", \" \", x)\n",
    "    tokens = essay_v.lower().split()\n",
    "    no_sw = remove_stopwords(tokens)\n",
    "    root = lemmatize(no_sw)\n",
    "    cleaned = ' '.join(root)\n",
    "    return cleaned\n",
    "\n",
    "def clean_tokenize(x):\n",
    "    #tokens = re.sub(\"[^a-zA-Z]\", \" \", x.lower())\n",
    "    essay_v = re.sub(\"[^a-zA-Z]\", \" \", x)\n",
    "    tokens = essay_v.lower().split()\n",
    "    no_sw = remove_stopwords(tokens)\n",
    "    root = lemmatize(no_sw)\n",
    "    return root\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer=clean_tokenize)\n",
    "feat_df = df[['statement_length', 'word_count', 'sentence_count', 'unique_words', 'lexical_richness', 'punctuation_count', 'noun_%', 'pronoun_%', 'verb_%', 'adj_%', 'determiner_%', 'foreign_%','emotion', 'profanity']]\n",
    "X = pd.concat([pd.DataFrame(vectorizer.fit_transform(df['Statement']).toarray()), feat_df], axis = 1)\n",
    "y = df['Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>lexical_richness</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>noun_%</th>\n",
       "      <th>pronoun_%</th>\n",
       "      <th>verb_%</th>\n",
       "      <th>adj_%</th>\n",
       "      <th>determiner_%</th>\n",
       "      <th>foreign_%</th>\n",
       "      <th>emotion</th>\n",
       "      <th>profanity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Happy</td>\n",
       "      <td>0.008152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>123.48</td>\n",
       "      <td>2</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>0.056929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>101.08</td>\n",
       "      <td>2</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>0.039250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fear</td>\n",
       "      <td>0.030024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.00</td>\n",
       "      <td>6</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>0.008631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>102.06</td>\n",
       "      <td>6</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fear</td>\n",
       "      <td>0.121310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>112.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fear</td>\n",
       "      <td>0.049405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fear</td>\n",
       "      <td>0.005492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Happy</td>\n",
       "      <td>0.297600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>80.92</td>\n",
       "      <td>1</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fear</td>\n",
       "      <td>0.074195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1140 rows × 3564 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6    7    8    9  ...  lexical_richness  \\\n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...             10.00   \n",
       "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...            123.48   \n",
       "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...            101.08   \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...             12.00   \n",
       "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...             16.00   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...               ...   \n",
       "1135  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...            102.06   \n",
       "1136  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...            112.00   \n",
       "1137  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...             17.00   \n",
       "1138  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...             17.00   \n",
       "1139  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...             80.92   \n",
       "\n",
       "      punctuation_count    noun_%  pronoun_%    verb_%     adj_%  \\\n",
       "0                     7  0.157895   0.000000  0.000000  0.052632   \n",
       "1                     2  0.407407   0.000000  0.185185  0.111111   \n",
       "2                     2  0.428571   0.035714  0.071429  0.071429   \n",
       "3                     4  0.312500   0.000000  0.062500  0.000000   \n",
       "4                     6  0.272727   0.090909  0.136364  0.000000   \n",
       "...                 ...       ...        ...       ...       ...   \n",
       "1135                  6  0.454545   0.030303  0.030303  0.000000   \n",
       "1136                  7  0.307692   0.038462  0.038462  0.000000   \n",
       "1137                  2  0.380952   0.000000  0.142857  0.095238   \n",
       "1138                  1  0.450000   0.050000  0.200000  0.050000   \n",
       "1139                  1  0.521739   0.000000  0.086957  0.043478   \n",
       "\n",
       "      determiner_%  foreign_%   emotion  profanity  \n",
       "0         0.105263        0.0     Happy   0.008152  \n",
       "1         0.074074        0.0  Surprise   0.056929  \n",
       "2         0.071429        0.0  Surprise   0.039250  \n",
       "3         0.062500        0.0      Fear   0.030024  \n",
       "4         0.045455        0.0  Surprise   0.008631  \n",
       "...            ...        ...       ...        ...  \n",
       "1135      0.090909        0.0      Fear   0.121310  \n",
       "1136      0.076923        0.0      Fear   0.049405  \n",
       "1137      0.047619        0.0      Fear   0.005492  \n",
       "1138      0.000000        0.0     Happy   0.297600  \n",
       "1139      0.130435        0.0      Fear   0.074195  \n",
       "\n",
       "[1140 rows x 3564 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns = X.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>lexical_richness</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>noun_%</th>\n",
       "      <th>pronoun_%</th>\n",
       "      <th>verb_%</th>\n",
       "      <th>adj_%</th>\n",
       "      <th>determiner_%</th>\n",
       "      <th>foreign_%</th>\n",
       "      <th>emotion</th>\n",
       "      <th>profanity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Happy</td>\n",
       "      <td>0.008152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>123.48</td>\n",
       "      <td>2</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>0.056929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>101.08</td>\n",
       "      <td>2</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>0.039250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.00</td>\n",
       "      <td>4</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fear</td>\n",
       "      <td>0.030024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.00</td>\n",
       "      <td>6</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>0.008631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>102.06</td>\n",
       "      <td>6</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fear</td>\n",
       "      <td>0.121310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>112.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fear</td>\n",
       "      <td>0.049405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fear</td>\n",
       "      <td>0.005492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Happy</td>\n",
       "      <td>0.297600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>80.92</td>\n",
       "      <td>1</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fear</td>\n",
       "      <td>0.074195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1140 rows × 3564 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6    7    8    9  ...  lexical_richness  \\\n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...             10.00   \n",
       "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...            123.48   \n",
       "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...            101.08   \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...             12.00   \n",
       "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...             16.00   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...               ...   \n",
       "1135  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...            102.06   \n",
       "1136  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...            112.00   \n",
       "1137  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...             17.00   \n",
       "1138  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...             17.00   \n",
       "1139  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...             80.92   \n",
       "\n",
       "      punctuation_count    noun_%  pronoun_%    verb_%     adj_%  \\\n",
       "0                     7  0.157895   0.000000  0.000000  0.052632   \n",
       "1                     2  0.407407   0.000000  0.185185  0.111111   \n",
       "2                     2  0.428571   0.035714  0.071429  0.071429   \n",
       "3                     4  0.312500   0.000000  0.062500  0.000000   \n",
       "4                     6  0.272727   0.090909  0.136364  0.000000   \n",
       "...                 ...       ...        ...       ...       ...   \n",
       "1135                  6  0.454545   0.030303  0.030303  0.000000   \n",
       "1136                  7  0.307692   0.038462  0.038462  0.000000   \n",
       "1137                  2  0.380952   0.000000  0.142857  0.095238   \n",
       "1138                  1  0.450000   0.050000  0.200000  0.050000   \n",
       "1139                  1  0.521739   0.000000  0.086957  0.043478   \n",
       "\n",
       "      determiner_%  foreign_%   emotion  profanity  \n",
       "0         0.105263        0.0     Happy   0.008152  \n",
       "1         0.074074        0.0  Surprise   0.056929  \n",
       "2         0.071429        0.0  Surprise   0.039250  \n",
       "3         0.062500        0.0      Fear   0.030024  \n",
       "4         0.045455        0.0  Surprise   0.008631  \n",
       "...            ...        ...       ...        ...  \n",
       "1135      0.090909        0.0      Fear   0.121310  \n",
       "1136      0.076923        0.0      Fear   0.049405  \n",
       "1137      0.047619        0.0      Fear   0.005492  \n",
       "1138      0.000000        0.0     Happy   0.297600  \n",
       "1139      0.130435        0.0      Fear   0.074195  \n",
       "\n",
       "[1140 rows x 3564 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import joblib\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "num_cols = ['statement_length', 'word_count', 'sentence_count', 'unique_words', 'lexical_richness', 'punctuation_count']\n",
    "cat_cols = ['emotion']\n",
    "\n",
    "\n",
    "ct = ColumnTransformer([('standard_scaler', StandardScaler(), num_cols),\n",
    "                        ('one_hot_encoder', OneHotEncoder(sparse=False, handle_unknown= \"ignore\"), cat_cols)], \n",
    "                        remainder='passthrough')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, f1_score\n",
    "\n",
    "clfXGB_nocv= Pipeline(steps = [('preprocessor', ct), ('XGBoost', XGBClassifier())])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carloalmeda/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;standard_scaler&#x27;,\n",
       "                                                  StandardScaler(),\n",
       "                                                  [&#x27;statement_length&#x27;,\n",
       "                                                   &#x27;word_count&#x27;,\n",
       "                                                   &#x27;sentence_count&#x27;,\n",
       "                                                   &#x27;unique_words&#x27;,\n",
       "                                                   &#x27;lexical_richness&#x27;,\n",
       "                                                   &#x27;punctuation_count&#x27;]),\n",
       "                                                 (&#x27;one_hot_encoder&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse=False),\n",
       "                                                  [&#x27;emotion&#x27;])])),\n",
       "                (&#x27;XGBoost&#x27;,\n",
       "                 XGBClassifier(base_sco...\n",
       "                               feature_types=None, gamma=0, gpu_id=-1,\n",
       "                               grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "                               interaction_constraints=&#x27;&#x27;,\n",
       "                               learning_rate=0.300000012, max_bin=256,\n",
       "                               max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "                               max_delta_step=0, max_depth=6, max_leaves=0,\n",
       "                               min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "                               n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;,\n",
       "                               random_state=0, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;standard_scaler&#x27;,\n",
       "                                                  StandardScaler(),\n",
       "                                                  [&#x27;statement_length&#x27;,\n",
       "                                                   &#x27;word_count&#x27;,\n",
       "                                                   &#x27;sentence_count&#x27;,\n",
       "                                                   &#x27;unique_words&#x27;,\n",
       "                                                   &#x27;lexical_richness&#x27;,\n",
       "                                                   &#x27;punctuation_count&#x27;]),\n",
       "                                                 (&#x27;one_hot_encoder&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse=False),\n",
       "                                                  [&#x27;emotion&#x27;])])),\n",
       "                (&#x27;XGBoost&#x27;,\n",
       "                 XGBClassifier(base_sco...\n",
       "                               feature_types=None, gamma=0, gpu_id=-1,\n",
       "                               grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "                               interaction_constraints=&#x27;&#x27;,\n",
       "                               learning_rate=0.300000012, max_bin=256,\n",
       "                               max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "                               max_delta_step=0, max_depth=6, max_leaves=0,\n",
       "                               min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "                               n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;,\n",
       "                               random_state=0, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;standard_scaler&#x27;, StandardScaler(),\n",
       "                                 [&#x27;statement_length&#x27;, &#x27;word_count&#x27;,\n",
       "                                  &#x27;sentence_count&#x27;, &#x27;unique_words&#x27;,\n",
       "                                  &#x27;lexical_richness&#x27;, &#x27;punctuation_count&#x27;]),\n",
       "                                (&#x27;one_hot_encoder&#x27;,\n",
       "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                               sparse=False),\n",
       "                                 [&#x27;emotion&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">standard_scaler</label><div class=\"sk-toggleable__content\"><pre>[&#x27;statement_length&#x27;, &#x27;word_count&#x27;, &#x27;sentence_count&#x27;, &#x27;unique_words&#x27;, &#x27;lexical_richness&#x27;, &#x27;punctuation_count&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">one_hot_encoder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;emotion&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;0&#x27;, &#x27;1&#x27;, &#x27;2&#x27;, &#x27;3&#x27;, &#x27;4&#x27;, &#x27;5&#x27;, &#x27;6&#x27;, &#x27;7&#x27;, &#x27;8&#x27;, &#x27;9&#x27;, &#x27;10&#x27;, &#x27;11&#x27;, &#x27;12&#x27;, &#x27;13&#x27;, &#x27;14&#x27;, &#x27;15&#x27;, &#x27;16&#x27;, &#x27;17&#x27;, &#x27;18&#x27;, &#x27;19&#x27;, &#x27;20&#x27;, &#x27;21&#x27;, &#x27;22&#x27;, &#x27;23&#x27;, &#x27;24&#x27;, &#x27;25&#x27;, &#x27;26&#x27;, &#x27;27&#x27;, &#x27;28&#x27;, &#x27;29&#x27;, &#x27;30&#x27;, &#x27;31&#x27;, &#x27;32&#x27;, &#x27;33&#x27;, &#x27;34&#x27;, &#x27;35&#x27;, &#x27;36&#x27;, &#x27;37&#x27;, &#x27;38&#x27;, &#x27;39&#x27;, &#x27;40&#x27;, &#x27;41&#x27;, &#x27;42&#x27;, &#x27;43&#x27;, &#x27;44&#x27;, &#x27;45&#x27;, &#x27;46&#x27;, &#x27;47&#x27;, &#x27;48&#x27;, &#x27;49&#x27;, &#x27;50&#x27;, &#x27;51&#x27;, &#x27;52&#x27;, &#x27;53&#x27;, &#x27;54&#x27;, &#x27;55&#x27;, &#x27;56&#x27;, &#x27;57&#x27;, &#x27;58&#x27;, &#x27;59&#x27;, &#x27;60&#x27;, &#x27;61&#x27;, &#x27;62&#x27;, &#x27;63&#x27;, &#x27;64&#x27;, &#x27;65&#x27;, &#x27;66&#x27;, &#x27;67&#x27;, &#x27;68&#x27;, &#x27;69&#x27;, &#x27;70&#x27;, &#x27;71&#x27;, &#x27;72&#x27;, &#x27;73&#x27;, &#x27;74&#x27;, &#x27;75&#x27;, &#x27;76&#x27;, &#x27;77&#x27;, &#x27;78&#x27;, &#x27;79&#x27;, &#x27;80&#x27;, &#x27;81&#x27;, &#x27;82&#x27;, &#x27;83&#x27;, &#x27;84&#x27;, &#x27;85&#x27;, &#x27;86&#x27;, &#x27;87&#x27;, &#x27;88&#x27;, &#x27;89&#x27;, &#x27;90&#x27;, &#x27;91&#x27;, &#x27;92&#x27;, &#x27;93&#x27;, &#x27;94&#x27;, &#x27;95&#x27;, &#x27;96&#x27;, &#x27;97&#x27;, &#x27;98&#x27;, &#x27;99&#x27;, &#x27;100&#x27;, &#x27;101&#x27;, &#x27;102&#x27;, &#x27;103&#x27;, &#x27;104&#x27;, &#x27;105&#x27;, &#x27;106&#x27;, &#x27;107&#x27;, &#x27;108&#x27;, &#x27;109&#x27;, &#x27;110&#x27;, &#x27;111&#x27;, &#x27;112&#x27;, &#x27;113&#x27;, &#x27;114&#x27;, &#x27;115&#x27;, &#x27;116&#x27;, &#x27;117&#x27;, &#x27;118&#x27;, &#x27;119&#x27;, &#x27;120&#x27;, &#x27;121&#x27;, &#x27;122&#x27;, &#x27;123&#x27;, &#x27;124&#x27;, &#x27;125&#x27;, &#x27;126&#x27;, &#x27;127&#x27;, &#x27;128&#x27;, &#x27;129&#x27;, &#x27;130&#x27;, &#x27;131&#x27;, &#x27;132&#x27;, &#x27;133&#x27;, &#x27;134&#x27;, &#x27;135&#x27;, &#x27;136&#x27;, &#x27;137&#x27;, &#x27;138&#x27;, &#x27;139&#x27;, &#x27;140&#x27;, &#x27;141&#x27;, &#x27;142&#x27;, &#x27;143&#x27;, &#x27;144&#x27;, &#x27;145&#x27;, &#x27;146&#x27;, &#x27;147&#x27;, &#x27;148&#x27;, &#x27;149&#x27;, &#x27;150&#x27;, &#x27;151&#x27;, &#x27;152&#x27;, &#x27;153&#x27;, &#x27;154&#x27;, &#x27;155&#x27;, &#x27;156&#x27;, &#x27;157&#x27;, &#x27;158&#x27;, &#x27;159&#x27;, &#x27;160&#x27;, &#x27;161&#x27;, &#x27;162&#x27;, &#x27;163&#x27;, &#x27;164&#x27;, &#x27;165&#x27;, &#x27;166&#x27;, &#x27;167&#x27;, &#x27;168&#x27;, &#x27;169&#x27;, &#x27;170&#x27;, &#x27;171&#x27;, &#x27;172&#x27;, &#x27;173&#x27;, &#x27;174&#x27;, &#x27;175&#x27;, &#x27;176&#x27;, &#x27;177&#x27;, &#x27;178&#x27;, &#x27;179&#x27;, &#x27;180&#x27;, &#x27;181&#x27;, &#x27;182&#x27;, &#x27;183&#x27;, &#x27;184&#x27;, &#x27;185&#x27;, &#x27;186&#x27;, &#x27;187&#x27;, &#x27;188&#x27;, &#x27;189&#x27;, &#x27;190&#x27;, &#x27;191&#x27;, &#x27;192&#x27;, &#x27;193&#x27;, &#x27;194&#x27;, &#x27;195&#x27;, &#x27;196&#x27;, &#x27;197&#x27;, &#x27;198&#x27;, &#x27;199&#x27;, &#x27;200&#x27;, &#x27;201&#x27;, &#x27;202&#x27;, &#x27;203&#x27;, &#x27;204&#x27;, &#x27;205&#x27;, &#x27;206&#x27;, &#x27;207&#x27;, &#x27;208&#x27;, &#x27;209&#x27;, &#x27;210&#x27;, &#x27;211&#x27;, &#x27;212&#x27;, &#x27;213&#x27;, &#x27;214&#x27;, &#x27;215&#x27;, &#x27;216&#x27;, &#x27;217&#x27;, &#x27;218&#x27;, &#x27;219&#x27;, &#x27;220&#x27;, &#x27;221&#x27;, &#x27;222&#x27;, &#x27;223&#x27;, &#x27;224&#x27;, &#x27;225&#x27;, &#x27;226&#x27;, &#x27;227&#x27;, &#x27;228&#x27;, &#x27;229&#x27;, &#x27;230&#x27;, &#x27;231&#x27;, &#x27;232&#x27;, &#x27;233&#x27;, &#x27;234&#x27;, &#x27;235&#x27;, &#x27;236&#x27;, &#x27;237&#x27;, &#x27;238&#x27;, &#x27;239&#x27;, &#x27;240&#x27;, &#x27;241&#x27;, &#x27;242&#x27;, &#x27;243&#x27;, &#x27;244&#x27;, &#x27;245&#x27;, &#x27;246&#x27;, &#x27;247&#x27;, &#x27;248&#x27;, &#x27;249&#x27;, &#x27;250&#x27;, &#x27;251&#x27;, &#x27;252&#x27;, &#x27;253&#x27;, &#x27;254&#x27;, &#x27;255&#x27;, &#x27;256&#x27;, &#x27;257&#x27;, &#x27;258&#x27;, &#x27;259&#x27;, &#x27;260&#x27;, &#x27;261&#x27;, &#x27;262&#x27;, &#x27;263&#x27;, &#x27;264&#x27;, &#x27;265&#x27;, &#x27;266&#x27;, &#x27;267&#x27;, &#x27;268&#x27;, &#x27;269&#x27;, &#x27;270&#x27;, &#x27;271&#x27;, &#x27;272&#x27;, &#x27;273&#x27;, &#x27;274&#x27;, &#x27;275&#x27;, &#x27;276&#x27;, &#x27;277&#x27;, &#x27;278&#x27;, &#x27;279&#x27;, &#x27;280&#x27;, &#x27;281&#x27;, &#x27;282&#x27;, &#x27;283&#x27;, &#x27;284&#x27;, &#x27;285&#x27;, &#x27;286&#x27;, &#x27;287&#x27;, &#x27;288&#x27;, &#x27;289&#x27;, &#x27;290&#x27;, &#x27;291&#x27;, &#x27;292&#x27;, &#x27;293&#x27;, &#x27;294&#x27;, &#x27;295&#x27;, &#x27;296&#x27;, &#x27;297&#x27;, &#x27;298&#x27;, &#x27;299&#x27;, &#x27;300&#x27;, &#x27;301&#x27;, &#x27;302&#x27;, &#x27;303&#x27;, &#x27;304&#x27;, &#x27;305&#x27;, &#x27;306&#x27;, &#x27;307&#x27;, &#x27;308&#x27;, &#x27;309&#x27;, &#x27;310&#x27;, &#x27;311&#x27;, &#x27;312&#x27;, &#x27;313&#x27;, &#x27;314&#x27;, &#x27;315&#x27;, &#x27;316&#x27;, &#x27;317&#x27;, &#x27;318&#x27;, &#x27;319&#x27;, &#x27;320&#x27;, &#x27;321&#x27;, &#x27;322&#x27;, &#x27;323&#x27;, &#x27;324&#x27;, &#x27;325&#x27;, &#x27;326&#x27;, &#x27;327&#x27;, &#x27;328&#x27;, &#x27;329&#x27;, &#x27;330&#x27;, &#x27;331&#x27;, &#x27;332&#x27;, &#x27;333&#x27;, &#x27;334&#x27;, &#x27;335&#x27;, &#x27;336&#x27;, &#x27;337&#x27;, &#x27;338&#x27;, &#x27;339&#x27;, &#x27;340&#x27;, &#x27;341&#x27;, &#x27;342&#x27;, &#x27;343&#x27;, &#x27;344&#x27;, &#x27;345&#x27;, &#x27;346&#x27;, &#x27;347&#x27;, &#x27;348&#x27;, &#x27;349&#x27;, &#x27;350&#x27;, &#x27;351&#x27;, &#x27;352&#x27;, &#x27;353&#x27;, &#x27;354&#x27;, &#x27;355&#x27;, &#x27;356&#x27;, &#x27;357&#x27;, &#x27;358&#x27;, &#x27;359&#x27;, &#x27;360&#x27;, &#x27;361&#x27;, &#x27;362&#x27;, &#x27;363&#x27;, &#x27;364&#x27;, &#x27;365&#x27;, &#x27;366&#x27;, &#x27;367&#x27;, &#x27;368&#x27;, &#x27;369&#x27;, &#x27;370&#x27;, &#x27;371&#x27;, &#x27;372&#x27;, &#x27;373&#x27;, &#x27;374&#x27;, &#x27;375&#x27;, &#x27;376&#x27;, &#x27;377&#x27;, &#x27;378&#x27;, &#x27;379&#x27;, &#x27;380&#x27;, &#x27;381&#x27;, &#x27;382&#x27;, &#x27;383&#x27;, &#x27;384&#x27;, &#x27;385&#x27;, &#x27;386&#x27;, &#x27;387&#x27;, &#x27;388&#x27;, &#x27;389&#x27;, &#x27;390&#x27;, &#x27;391&#x27;, &#x27;392&#x27;, &#x27;393&#x27;, &#x27;394&#x27;, &#x27;395&#x27;, &#x27;396&#x27;, &#x27;397&#x27;, &#x27;398&#x27;, &#x27;399&#x27;, &#x27;400&#x27;, &#x27;401&#x27;, &#x27;402&#x27;, &#x27;403&#x27;, &#x27;404&#x27;, &#x27;405&#x27;, &#x27;406&#x27;, &#x27;407&#x27;, &#x27;408&#x27;, &#x27;409&#x27;, &#x27;410&#x27;, &#x27;411&#x27;, &#x27;412&#x27;, &#x27;413&#x27;, &#x27;414&#x27;, &#x27;415&#x27;, &#x27;416&#x27;, &#x27;417&#x27;, &#x27;418&#x27;, &#x27;419&#x27;, &#x27;420&#x27;, &#x27;421&#x27;, &#x27;422&#x27;, &#x27;423&#x27;, &#x27;424&#x27;, &#x27;425&#x27;, &#x27;426&#x27;, &#x27;427&#x27;, &#x27;428&#x27;, &#x27;429&#x27;, &#x27;430&#x27;, &#x27;431&#x27;, &#x27;432&#x27;, &#x27;433&#x27;, &#x27;434&#x27;, &#x27;435&#x27;, &#x27;436&#x27;, &#x27;437&#x27;, &#x27;438&#x27;, &#x27;439&#x27;, &#x27;440&#x27;, &#x27;441&#x27;, &#x27;442&#x27;, &#x27;443&#x27;, &#x27;444&#x27;, &#x27;445&#x27;, &#x27;446&#x27;, &#x27;447&#x27;, &#x27;448&#x27;, &#x27;449&#x27;, &#x27;450&#x27;, &#x27;451&#x27;, &#x27;452&#x27;, &#x27;453&#x27;, &#x27;454&#x27;, &#x27;455&#x27;, &#x27;456&#x27;, &#x27;457&#x27;, &#x27;458&#x27;, &#x27;459&#x27;, &#x27;460&#x27;, &#x27;461&#x27;, &#x27;462&#x27;, &#x27;463&#x27;, &#x27;464&#x27;, &#x27;465&#x27;, &#x27;466&#x27;, &#x27;467&#x27;, &#x27;468&#x27;, &#x27;469&#x27;, &#x27;470&#x27;, &#x27;471&#x27;, &#x27;472&#x27;, &#x27;473&#x27;, &#x27;474&#x27;, &#x27;475&#x27;, &#x27;476&#x27;, &#x27;477&#x27;, &#x27;478&#x27;, &#x27;479&#x27;, &#x27;480&#x27;, &#x27;481&#x27;, &#x27;482&#x27;, &#x27;483&#x27;, &#x27;484&#x27;, &#x27;485&#x27;, &#x27;486&#x27;, &#x27;487&#x27;, &#x27;488&#x27;, &#x27;489&#x27;, &#x27;490&#x27;, &#x27;491&#x27;, &#x27;492&#x27;, &#x27;493&#x27;, &#x27;494&#x27;, &#x27;495&#x27;, &#x27;496&#x27;, &#x27;497&#x27;, &#x27;498&#x27;, &#x27;499&#x27;, &#x27;500&#x27;, &#x27;501&#x27;, &#x27;502&#x27;, &#x27;503&#x27;, &#x27;504&#x27;, &#x27;505&#x27;, &#x27;506&#x27;, &#x27;507&#x27;, &#x27;508&#x27;, &#x27;509&#x27;, &#x27;510&#x27;, &#x27;511&#x27;, &#x27;512&#x27;, &#x27;513&#x27;, &#x27;514&#x27;, &#x27;515&#x27;, &#x27;516&#x27;, &#x27;517&#x27;, &#x27;518&#x27;, &#x27;519&#x27;, &#x27;520&#x27;, &#x27;521&#x27;, &#x27;522&#x27;, &#x27;523&#x27;, &#x27;524&#x27;, &#x27;525&#x27;, &#x27;526&#x27;, &#x27;527&#x27;, &#x27;528&#x27;, &#x27;529&#x27;, &#x27;530&#x27;, &#x27;531&#x27;, &#x27;532&#x27;, &#x27;533&#x27;, &#x27;534&#x27;, &#x27;535&#x27;, &#x27;536&#x27;, &#x27;537&#x27;, &#x27;538&#x27;, &#x27;539&#x27;, &#x27;540&#x27;, &#x27;541&#x27;, &#x27;542&#x27;, &#x27;543&#x27;, &#x27;544&#x27;, &#x27;545&#x27;, &#x27;546&#x27;, &#x27;547&#x27;, &#x27;548&#x27;, &#x27;549&#x27;, &#x27;550&#x27;, &#x27;551&#x27;, &#x27;552&#x27;, &#x27;553&#x27;, &#x27;554&#x27;, &#x27;555&#x27;, &#x27;556&#x27;, &#x27;557&#x27;, &#x27;558&#x27;, &#x27;559&#x27;, &#x27;560&#x27;, &#x27;561&#x27;, &#x27;562&#x27;, &#x27;563&#x27;, &#x27;564&#x27;, &#x27;565&#x27;, &#x27;566&#x27;, &#x27;567&#x27;, &#x27;568&#x27;, &#x27;569&#x27;, &#x27;570&#x27;, &#x27;571&#x27;, &#x27;572&#x27;, &#x27;573&#x27;, &#x27;574&#x27;, &#x27;575&#x27;, &#x27;576&#x27;, &#x27;577&#x27;, &#x27;578&#x27;, &#x27;579&#x27;, &#x27;580&#x27;, &#x27;581&#x27;, &#x27;582&#x27;, &#x27;583&#x27;, &#x27;584&#x27;, &#x27;585&#x27;, &#x27;586&#x27;, &#x27;587&#x27;, &#x27;588&#x27;, &#x27;589&#x27;, &#x27;590&#x27;, &#x27;591&#x27;, &#x27;592&#x27;, &#x27;593&#x27;, &#x27;594&#x27;, &#x27;595&#x27;, &#x27;596&#x27;, &#x27;597&#x27;, &#x27;598&#x27;, &#x27;599&#x27;, &#x27;600&#x27;, &#x27;601&#x27;, &#x27;602&#x27;, &#x27;603&#x27;, &#x27;604&#x27;, &#x27;605&#x27;, &#x27;606&#x27;, &#x27;607&#x27;, &#x27;608&#x27;, &#x27;609&#x27;, &#x27;610&#x27;, &#x27;611&#x27;, &#x27;612&#x27;, &#x27;613&#x27;, &#x27;614&#x27;, &#x27;615&#x27;, &#x27;616&#x27;, &#x27;617&#x27;, &#x27;618&#x27;, &#x27;619&#x27;, &#x27;620&#x27;, &#x27;621&#x27;, &#x27;622&#x27;, &#x27;623&#x27;, &#x27;624&#x27;, &#x27;625&#x27;, &#x27;626&#x27;, &#x27;627&#x27;, &#x27;628&#x27;, &#x27;629&#x27;, &#x27;630&#x27;, &#x27;631&#x27;, &#x27;632&#x27;, &#x27;633&#x27;, &#x27;634&#x27;, &#x27;635&#x27;, &#x27;636&#x27;, &#x27;637&#x27;, &#x27;638&#x27;, &#x27;639&#x27;, &#x27;640&#x27;, &#x27;641&#x27;, &#x27;642&#x27;, &#x27;643&#x27;, &#x27;644&#x27;, &#x27;645&#x27;, &#x27;646&#x27;, &#x27;647&#x27;, &#x27;648&#x27;, &#x27;649&#x27;, &#x27;650&#x27;, &#x27;651&#x27;, &#x27;652&#x27;, &#x27;653&#x27;, &#x27;654&#x27;, &#x27;655&#x27;, &#x27;656&#x27;, &#x27;657&#x27;, &#x27;658&#x27;, &#x27;659&#x27;, &#x27;660&#x27;, &#x27;661&#x27;, &#x27;662&#x27;, &#x27;663&#x27;, &#x27;664&#x27;, &#x27;665&#x27;, &#x27;666&#x27;, &#x27;667&#x27;, &#x27;668&#x27;, &#x27;669&#x27;, &#x27;670&#x27;, &#x27;671&#x27;, &#x27;672&#x27;, &#x27;673&#x27;, &#x27;674&#x27;, &#x27;675&#x27;, &#x27;676&#x27;, &#x27;677&#x27;, &#x27;678&#x27;, &#x27;679&#x27;, &#x27;680&#x27;, &#x27;681&#x27;, &#x27;682&#x27;, &#x27;683&#x27;, &#x27;684&#x27;, &#x27;685&#x27;, &#x27;686&#x27;, &#x27;687&#x27;, &#x27;688&#x27;, &#x27;689&#x27;, &#x27;690&#x27;, &#x27;691&#x27;, &#x27;692&#x27;, &#x27;693&#x27;, &#x27;694&#x27;, &#x27;695&#x27;, &#x27;696&#x27;, &#x27;697&#x27;, &#x27;698&#x27;, &#x27;699&#x27;, &#x27;700&#x27;, &#x27;701&#x27;, &#x27;702&#x27;, &#x27;703&#x27;, &#x27;704&#x27;, &#x27;705&#x27;, &#x27;706&#x27;, &#x27;707&#x27;, &#x27;708&#x27;, &#x27;709&#x27;, &#x27;710&#x27;, &#x27;711&#x27;, &#x27;712&#x27;, &#x27;713&#x27;, &#x27;714&#x27;, &#x27;715&#x27;, &#x27;716&#x27;, &#x27;717&#x27;, &#x27;718&#x27;, &#x27;719&#x27;, &#x27;720&#x27;, &#x27;721&#x27;, &#x27;722&#x27;, &#x27;723&#x27;, &#x27;724&#x27;, &#x27;725&#x27;, &#x27;726&#x27;, &#x27;727&#x27;, &#x27;728&#x27;, &#x27;729&#x27;, &#x27;730&#x27;, &#x27;731&#x27;, &#x27;732&#x27;, &#x27;733&#x27;, &#x27;734&#x27;, &#x27;735&#x27;, &#x27;736&#x27;, &#x27;737&#x27;, &#x27;738&#x27;, &#x27;739&#x27;, &#x27;740&#x27;, &#x27;741&#x27;, &#x27;742&#x27;, &#x27;743&#x27;, &#x27;744&#x27;, &#x27;745&#x27;, &#x27;746&#x27;, &#x27;747&#x27;, &#x27;748&#x27;, &#x27;749&#x27;, &#x27;750&#x27;, &#x27;751&#x27;, &#x27;752&#x27;, &#x27;753&#x27;, &#x27;754&#x27;, &#x27;755&#x27;, &#x27;756&#x27;, &#x27;757&#x27;, &#x27;758&#x27;, &#x27;759&#x27;, &#x27;760&#x27;, &#x27;761&#x27;, &#x27;762&#x27;, &#x27;763&#x27;, &#x27;764&#x27;, &#x27;765&#x27;, &#x27;766&#x27;, &#x27;767&#x27;, &#x27;768&#x27;, &#x27;769&#x27;, &#x27;770&#x27;, &#x27;771&#x27;, &#x27;772&#x27;, &#x27;773&#x27;, &#x27;774&#x27;, &#x27;775&#x27;, &#x27;776&#x27;, &#x27;777&#x27;, &#x27;778&#x27;, &#x27;779&#x27;, &#x27;780&#x27;, &#x27;781&#x27;, &#x27;782&#x27;, &#x27;783&#x27;, &#x27;784&#x27;, &#x27;785&#x27;, &#x27;786&#x27;, &#x27;787&#x27;, &#x27;788&#x27;, &#x27;789&#x27;, &#x27;790&#x27;, &#x27;791&#x27;, &#x27;792&#x27;, &#x27;793&#x27;, &#x27;794&#x27;, &#x27;795&#x27;, &#x27;796&#x27;, &#x27;797&#x27;, &#x27;798&#x27;, &#x27;799&#x27;, &#x27;800&#x27;, &#x27;801&#x27;, &#x27;802&#x27;, &#x27;803&#x27;, &#x27;804&#x27;, &#x27;805&#x27;, &#x27;806&#x27;, &#x27;807&#x27;, &#x27;808&#x27;, &#x27;809&#x27;, &#x27;810&#x27;, &#x27;811&#x27;, &#x27;812&#x27;, &#x27;813&#x27;, &#x27;814&#x27;, &#x27;815&#x27;, &#x27;816&#x27;, &#x27;817&#x27;, &#x27;818&#x27;, &#x27;819&#x27;, &#x27;820&#x27;, &#x27;821&#x27;, &#x27;822&#x27;, &#x27;823&#x27;, &#x27;824&#x27;, &#x27;825&#x27;, &#x27;826&#x27;, &#x27;827&#x27;, &#x27;828&#x27;, &#x27;829&#x27;, &#x27;830&#x27;, &#x27;831&#x27;, &#x27;832&#x27;, &#x27;833&#x27;, &#x27;834&#x27;, &#x27;835&#x27;, &#x27;836&#x27;, &#x27;837&#x27;, &#x27;838&#x27;, &#x27;839&#x27;, &#x27;840&#x27;, &#x27;841&#x27;, &#x27;842&#x27;, &#x27;843&#x27;, &#x27;844&#x27;, &#x27;845&#x27;, &#x27;846&#x27;, &#x27;847&#x27;, &#x27;848&#x27;, &#x27;849&#x27;, &#x27;850&#x27;, &#x27;851&#x27;, &#x27;852&#x27;, &#x27;853&#x27;, &#x27;854&#x27;, &#x27;855&#x27;, &#x27;856&#x27;, &#x27;857&#x27;, &#x27;858&#x27;, &#x27;859&#x27;, &#x27;860&#x27;, &#x27;861&#x27;, &#x27;862&#x27;, &#x27;863&#x27;, &#x27;864&#x27;, &#x27;865&#x27;, &#x27;866&#x27;, &#x27;867&#x27;, &#x27;868&#x27;, &#x27;869&#x27;, &#x27;870&#x27;, &#x27;871&#x27;, &#x27;872&#x27;, &#x27;873&#x27;, &#x27;874&#x27;, &#x27;875&#x27;, &#x27;876&#x27;, &#x27;877&#x27;, &#x27;878&#x27;, &#x27;879&#x27;, &#x27;880&#x27;, &#x27;881&#x27;, &#x27;882&#x27;, &#x27;883&#x27;, &#x27;884&#x27;, &#x27;885&#x27;, &#x27;886&#x27;, &#x27;887&#x27;, &#x27;888&#x27;, &#x27;889&#x27;, &#x27;890&#x27;, &#x27;891&#x27;, &#x27;892&#x27;, &#x27;893&#x27;, &#x27;894&#x27;, &#x27;895&#x27;, &#x27;896&#x27;, &#x27;897&#x27;, &#x27;898&#x27;, &#x27;899&#x27;, &#x27;900&#x27;, &#x27;901&#x27;, &#x27;902&#x27;, &#x27;903&#x27;, &#x27;904&#x27;, &#x27;905&#x27;, &#x27;906&#x27;, &#x27;907&#x27;, &#x27;908&#x27;, &#x27;909&#x27;, &#x27;910&#x27;, &#x27;911&#x27;, &#x27;912&#x27;, &#x27;913&#x27;, &#x27;914&#x27;, &#x27;915&#x27;, &#x27;916&#x27;, &#x27;917&#x27;, &#x27;918&#x27;, &#x27;919&#x27;, &#x27;920&#x27;, &#x27;921&#x27;, &#x27;922&#x27;, &#x27;923&#x27;, &#x27;924&#x27;, &#x27;925&#x27;, &#x27;926&#x27;, &#x27;927&#x27;, &#x27;928&#x27;, &#x27;929&#x27;, &#x27;930&#x27;, &#x27;931&#x27;, &#x27;932&#x27;, &#x27;933&#x27;, &#x27;934&#x27;, &#x27;935&#x27;, &#x27;936&#x27;, &#x27;937&#x27;, &#x27;938&#x27;, &#x27;939&#x27;, &#x27;940&#x27;, &#x27;941&#x27;, &#x27;942&#x27;, &#x27;943&#x27;, &#x27;944&#x27;, &#x27;945&#x27;, &#x27;946&#x27;, &#x27;947&#x27;, &#x27;948&#x27;, &#x27;949&#x27;, &#x27;950&#x27;, &#x27;951&#x27;, &#x27;952&#x27;, &#x27;953&#x27;, &#x27;954&#x27;, &#x27;955&#x27;, &#x27;956&#x27;, &#x27;957&#x27;, &#x27;958&#x27;, &#x27;959&#x27;, &#x27;960&#x27;, &#x27;961&#x27;, &#x27;962&#x27;, &#x27;963&#x27;, &#x27;964&#x27;, &#x27;965&#x27;, &#x27;966&#x27;, &#x27;967&#x27;, &#x27;968&#x27;, &#x27;969&#x27;, &#x27;970&#x27;, &#x27;971&#x27;, &#x27;972&#x27;, &#x27;973&#x27;, &#x27;974&#x27;, &#x27;975&#x27;, &#x27;976&#x27;, &#x27;977&#x27;, &#x27;978&#x27;, &#x27;979&#x27;, &#x27;980&#x27;, &#x27;981&#x27;, &#x27;982&#x27;, &#x27;983&#x27;, &#x27;984&#x27;, &#x27;985&#x27;, &#x27;986&#x27;, &#x27;987&#x27;, &#x27;988&#x27;, &#x27;989&#x27;, &#x27;990&#x27;, &#x27;991&#x27;, &#x27;992&#x27;, &#x27;993&#x27;, &#x27;994&#x27;, &#x27;995&#x27;, &#x27;996&#x27;, &#x27;997&#x27;, &#x27;998&#x27;, &#x27;999&#x27;, &#x27;1000&#x27;, &#x27;1001&#x27;, &#x27;1002&#x27;, &#x27;1003&#x27;, &#x27;1004&#x27;, &#x27;1005&#x27;, &#x27;1006&#x27;, &#x27;1007&#x27;, &#x27;1008&#x27;, &#x27;1009&#x27;, &#x27;1010&#x27;, &#x27;1011&#x27;, &#x27;1012&#x27;, &#x27;1013&#x27;, &#x27;1014&#x27;, &#x27;1015&#x27;, &#x27;1016&#x27;, &#x27;1017&#x27;, &#x27;1018&#x27;, &#x27;1019&#x27;, &#x27;1020&#x27;, &#x27;1021&#x27;, &#x27;1022&#x27;, &#x27;1023&#x27;, &#x27;1024&#x27;, &#x27;1025&#x27;, &#x27;1026&#x27;, &#x27;1027&#x27;, &#x27;1028&#x27;, &#x27;1029&#x27;, &#x27;1030&#x27;, &#x27;1031&#x27;, &#x27;1032&#x27;, &#x27;1033&#x27;, &#x27;1034&#x27;, &#x27;1035&#x27;, &#x27;1036&#x27;, &#x27;1037&#x27;, &#x27;1038&#x27;, &#x27;1039&#x27;, &#x27;1040&#x27;, &#x27;1041&#x27;, &#x27;1042&#x27;, &#x27;1043&#x27;, &#x27;1044&#x27;, &#x27;1045&#x27;, &#x27;1046&#x27;, &#x27;1047&#x27;, &#x27;1048&#x27;, &#x27;1049&#x27;, &#x27;1050&#x27;, &#x27;1051&#x27;, &#x27;1052&#x27;, &#x27;1053&#x27;, &#x27;1054&#x27;, &#x27;1055&#x27;, &#x27;1056&#x27;, &#x27;1057&#x27;, &#x27;1058&#x27;, &#x27;1059&#x27;, &#x27;1060&#x27;, &#x27;1061&#x27;, &#x27;1062&#x27;, &#x27;1063&#x27;, &#x27;1064&#x27;, &#x27;1065&#x27;, &#x27;1066&#x27;, &#x27;1067&#x27;, &#x27;1068&#x27;, &#x27;1069&#x27;, &#x27;1070&#x27;, &#x27;1071&#x27;, &#x27;1072&#x27;, &#x27;1073&#x27;, &#x27;1074&#x27;, &#x27;1075&#x27;, &#x27;1076&#x27;, &#x27;1077&#x27;, &#x27;1078&#x27;, &#x27;1079&#x27;, &#x27;1080&#x27;, &#x27;1081&#x27;, &#x27;1082&#x27;, &#x27;1083&#x27;, &#x27;1084&#x27;, &#x27;1085&#x27;, &#x27;1086&#x27;, &#x27;1087&#x27;, &#x27;1088&#x27;, &#x27;1089&#x27;, &#x27;1090&#x27;, &#x27;1091&#x27;, &#x27;1092&#x27;, &#x27;1093&#x27;, &#x27;1094&#x27;, &#x27;1095&#x27;, &#x27;1096&#x27;, &#x27;1097&#x27;, &#x27;1098&#x27;, &#x27;1099&#x27;, &#x27;1100&#x27;, &#x27;1101&#x27;, &#x27;1102&#x27;, &#x27;1103&#x27;, &#x27;1104&#x27;, &#x27;1105&#x27;, &#x27;1106&#x27;, &#x27;1107&#x27;, &#x27;1108&#x27;, &#x27;1109&#x27;, &#x27;1110&#x27;, &#x27;1111&#x27;, &#x27;1112&#x27;, &#x27;1113&#x27;, &#x27;1114&#x27;, &#x27;1115&#x27;, &#x27;1116&#x27;, &#x27;1117&#x27;, &#x27;1118&#x27;, &#x27;1119&#x27;, &#x27;1120&#x27;, &#x27;1121&#x27;, &#x27;1122&#x27;, &#x27;1123&#x27;, &#x27;1124&#x27;, &#x27;1125&#x27;, &#x27;1126&#x27;, &#x27;1127&#x27;, &#x27;1128&#x27;, &#x27;1129&#x27;, &#x27;1130&#x27;, &#x27;1131&#x27;, &#x27;1132&#x27;, &#x27;1133&#x27;, &#x27;1134&#x27;, &#x27;1135&#x27;, &#x27;1136&#x27;, &#x27;1137&#x27;, &#x27;1138&#x27;, &#x27;1139&#x27;, &#x27;1140&#x27;, &#x27;1141&#x27;, &#x27;1142&#x27;, &#x27;1143&#x27;, &#x27;1144&#x27;, &#x27;1145&#x27;, &#x27;1146&#x27;, &#x27;1147&#x27;, &#x27;1148&#x27;, &#x27;1149&#x27;, &#x27;1150&#x27;, &#x27;1151&#x27;, &#x27;1152&#x27;, &#x27;1153&#x27;, &#x27;1154&#x27;, &#x27;1155&#x27;, &#x27;1156&#x27;, &#x27;1157&#x27;, &#x27;1158&#x27;, &#x27;1159&#x27;, &#x27;1160&#x27;, &#x27;1161&#x27;, &#x27;1162&#x27;, &#x27;1163&#x27;, &#x27;1164&#x27;, &#x27;1165&#x27;, &#x27;1166&#x27;, &#x27;1167&#x27;, &#x27;1168&#x27;, &#x27;1169&#x27;, &#x27;1170&#x27;, &#x27;1171&#x27;, &#x27;1172&#x27;, &#x27;1173&#x27;, &#x27;1174&#x27;, &#x27;1175&#x27;, &#x27;1176&#x27;, &#x27;1177&#x27;, &#x27;1178&#x27;, &#x27;1179&#x27;, &#x27;1180&#x27;, &#x27;1181&#x27;, &#x27;1182&#x27;, &#x27;1183&#x27;, &#x27;1184&#x27;, &#x27;1185&#x27;, &#x27;1186&#x27;, &#x27;1187&#x27;, &#x27;1188&#x27;, &#x27;1189&#x27;, &#x27;1190&#x27;, &#x27;1191&#x27;, &#x27;1192&#x27;, &#x27;1193&#x27;, &#x27;1194&#x27;, &#x27;1195&#x27;, &#x27;1196&#x27;, &#x27;1197&#x27;, &#x27;1198&#x27;, &#x27;1199&#x27;, &#x27;1200&#x27;, &#x27;1201&#x27;, &#x27;1202&#x27;, &#x27;1203&#x27;, &#x27;1204&#x27;, &#x27;1205&#x27;, &#x27;1206&#x27;, &#x27;1207&#x27;, &#x27;1208&#x27;, &#x27;1209&#x27;, &#x27;1210&#x27;, &#x27;1211&#x27;, &#x27;1212&#x27;, &#x27;1213&#x27;, &#x27;1214&#x27;, &#x27;1215&#x27;, &#x27;1216&#x27;, &#x27;1217&#x27;, &#x27;1218&#x27;, &#x27;1219&#x27;, &#x27;1220&#x27;, &#x27;1221&#x27;, &#x27;1222&#x27;, &#x27;1223&#x27;, &#x27;1224&#x27;, &#x27;1225&#x27;, &#x27;1226&#x27;, &#x27;1227&#x27;, &#x27;1228&#x27;, &#x27;1229&#x27;, &#x27;1230&#x27;, &#x27;1231&#x27;, &#x27;1232&#x27;, &#x27;1233&#x27;, &#x27;1234&#x27;, &#x27;1235&#x27;, &#x27;1236&#x27;, &#x27;1237&#x27;, &#x27;1238&#x27;, &#x27;1239&#x27;, &#x27;1240&#x27;, &#x27;1241&#x27;, &#x27;1242&#x27;, &#x27;1243&#x27;, &#x27;1244&#x27;, &#x27;1245&#x27;, &#x27;1246&#x27;, &#x27;1247&#x27;, &#x27;1248&#x27;, &#x27;1249&#x27;, &#x27;1250&#x27;, &#x27;1251&#x27;, &#x27;1252&#x27;, &#x27;1253&#x27;, &#x27;1254&#x27;, &#x27;1255&#x27;, &#x27;1256&#x27;, &#x27;1257&#x27;, &#x27;1258&#x27;, &#x27;1259&#x27;, &#x27;1260&#x27;, &#x27;1261&#x27;, &#x27;1262&#x27;, &#x27;1263&#x27;, &#x27;1264&#x27;, &#x27;1265&#x27;, &#x27;1266&#x27;, &#x27;1267&#x27;, &#x27;1268&#x27;, &#x27;1269&#x27;, &#x27;1270&#x27;, &#x27;1271&#x27;, &#x27;1272&#x27;, &#x27;1273&#x27;, &#x27;1274&#x27;, &#x27;1275&#x27;, &#x27;1276&#x27;, &#x27;1277&#x27;, &#x27;1278&#x27;, &#x27;1279&#x27;, &#x27;1280&#x27;, &#x27;1281&#x27;, &#x27;1282&#x27;, &#x27;1283&#x27;, &#x27;1284&#x27;, &#x27;1285&#x27;, &#x27;1286&#x27;, &#x27;1287&#x27;, &#x27;1288&#x27;, &#x27;1289&#x27;, &#x27;1290&#x27;, &#x27;1291&#x27;, &#x27;1292&#x27;, &#x27;1293&#x27;, &#x27;1294&#x27;, &#x27;1295&#x27;, &#x27;1296&#x27;, &#x27;1297&#x27;, &#x27;1298&#x27;, &#x27;1299&#x27;, &#x27;1300&#x27;, &#x27;1301&#x27;, &#x27;1302&#x27;, &#x27;1303&#x27;, &#x27;1304&#x27;, &#x27;1305&#x27;, &#x27;1306&#x27;, &#x27;1307&#x27;, &#x27;1308&#x27;, &#x27;1309&#x27;, &#x27;1310&#x27;, &#x27;1311&#x27;, &#x27;1312&#x27;, &#x27;1313&#x27;, &#x27;1314&#x27;, &#x27;1315&#x27;, &#x27;1316&#x27;, &#x27;1317&#x27;, &#x27;1318&#x27;, &#x27;1319&#x27;, &#x27;1320&#x27;, &#x27;1321&#x27;, &#x27;1322&#x27;, &#x27;1323&#x27;, &#x27;1324&#x27;, &#x27;1325&#x27;, &#x27;1326&#x27;, &#x27;1327&#x27;, &#x27;1328&#x27;, &#x27;1329&#x27;, &#x27;1330&#x27;, &#x27;1331&#x27;, &#x27;1332&#x27;, &#x27;1333&#x27;, &#x27;1334&#x27;, &#x27;1335&#x27;, &#x27;1336&#x27;, &#x27;1337&#x27;, &#x27;1338&#x27;, &#x27;1339&#x27;, &#x27;1340&#x27;, &#x27;1341&#x27;, &#x27;1342&#x27;, &#x27;1343&#x27;, &#x27;1344&#x27;, &#x27;1345&#x27;, &#x27;1346&#x27;, &#x27;1347&#x27;, &#x27;1348&#x27;, &#x27;1349&#x27;, &#x27;1350&#x27;, &#x27;1351&#x27;, &#x27;1352&#x27;, &#x27;1353&#x27;, &#x27;1354&#x27;, &#x27;1355&#x27;, &#x27;1356&#x27;, &#x27;1357&#x27;, &#x27;1358&#x27;, &#x27;1359&#x27;, &#x27;1360&#x27;, &#x27;1361&#x27;, &#x27;1362&#x27;, &#x27;1363&#x27;, &#x27;1364&#x27;, &#x27;1365&#x27;, &#x27;1366&#x27;, &#x27;1367&#x27;, &#x27;1368&#x27;, &#x27;1369&#x27;, &#x27;1370&#x27;, &#x27;1371&#x27;, &#x27;1372&#x27;, &#x27;1373&#x27;, &#x27;1374&#x27;, &#x27;1375&#x27;, &#x27;1376&#x27;, &#x27;1377&#x27;, &#x27;1378&#x27;, &#x27;1379&#x27;, &#x27;1380&#x27;, &#x27;1381&#x27;, &#x27;1382&#x27;, &#x27;1383&#x27;, &#x27;1384&#x27;, &#x27;1385&#x27;, &#x27;1386&#x27;, &#x27;1387&#x27;, &#x27;1388&#x27;, &#x27;1389&#x27;, &#x27;1390&#x27;, &#x27;1391&#x27;, &#x27;1392&#x27;, &#x27;1393&#x27;, &#x27;1394&#x27;, &#x27;1395&#x27;, &#x27;1396&#x27;, &#x27;1397&#x27;, &#x27;1398&#x27;, &#x27;1399&#x27;, &#x27;1400&#x27;, &#x27;1401&#x27;, &#x27;1402&#x27;, &#x27;1403&#x27;, &#x27;1404&#x27;, &#x27;1405&#x27;, &#x27;1406&#x27;, &#x27;1407&#x27;, &#x27;1408&#x27;, &#x27;1409&#x27;, &#x27;1410&#x27;, &#x27;1411&#x27;, &#x27;1412&#x27;, &#x27;1413&#x27;, &#x27;1414&#x27;, &#x27;1415&#x27;, &#x27;1416&#x27;, &#x27;1417&#x27;, &#x27;1418&#x27;, &#x27;1419&#x27;, &#x27;1420&#x27;, &#x27;1421&#x27;, &#x27;1422&#x27;, &#x27;1423&#x27;, &#x27;1424&#x27;, &#x27;1425&#x27;, &#x27;1426&#x27;, &#x27;1427&#x27;, &#x27;1428&#x27;, &#x27;1429&#x27;, &#x27;1430&#x27;, &#x27;1431&#x27;, &#x27;1432&#x27;, &#x27;1433&#x27;, &#x27;1434&#x27;, &#x27;1435&#x27;, &#x27;1436&#x27;, &#x27;1437&#x27;, &#x27;1438&#x27;, &#x27;1439&#x27;, &#x27;1440&#x27;, &#x27;1441&#x27;, &#x27;1442&#x27;, &#x27;1443&#x27;, &#x27;1444&#x27;, &#x27;1445&#x27;, &#x27;1446&#x27;, &#x27;1447&#x27;, &#x27;1448&#x27;, &#x27;1449&#x27;, &#x27;1450&#x27;, &#x27;1451&#x27;, &#x27;1452&#x27;, &#x27;1453&#x27;, &#x27;1454&#x27;, &#x27;1455&#x27;, &#x27;1456&#x27;, &#x27;1457&#x27;, &#x27;1458&#x27;, &#x27;1459&#x27;, &#x27;1460&#x27;, &#x27;1461&#x27;, &#x27;1462&#x27;, &#x27;1463&#x27;, &#x27;1464&#x27;, &#x27;1465&#x27;, &#x27;1466&#x27;, &#x27;1467&#x27;, &#x27;1468&#x27;, &#x27;1469&#x27;, &#x27;1470&#x27;, &#x27;1471&#x27;, &#x27;1472&#x27;, &#x27;1473&#x27;, &#x27;1474&#x27;, &#x27;1475&#x27;, &#x27;1476&#x27;, &#x27;1477&#x27;, &#x27;1478&#x27;, &#x27;1479&#x27;, &#x27;1480&#x27;, &#x27;1481&#x27;, &#x27;1482&#x27;, &#x27;1483&#x27;, &#x27;1484&#x27;, &#x27;1485&#x27;, &#x27;1486&#x27;, &#x27;1487&#x27;, &#x27;1488&#x27;, &#x27;1489&#x27;, &#x27;1490&#x27;, &#x27;1491&#x27;, &#x27;1492&#x27;, &#x27;1493&#x27;, &#x27;1494&#x27;, &#x27;1495&#x27;, &#x27;1496&#x27;, &#x27;1497&#x27;, &#x27;1498&#x27;, &#x27;1499&#x27;, &#x27;1500&#x27;, &#x27;1501&#x27;, &#x27;1502&#x27;, &#x27;1503&#x27;, &#x27;1504&#x27;, &#x27;1505&#x27;, &#x27;1506&#x27;, &#x27;1507&#x27;, &#x27;1508&#x27;, &#x27;1509&#x27;, &#x27;1510&#x27;, &#x27;1511&#x27;, &#x27;1512&#x27;, &#x27;1513&#x27;, &#x27;1514&#x27;, &#x27;1515&#x27;, &#x27;1516&#x27;, &#x27;1517&#x27;, &#x27;1518&#x27;, &#x27;1519&#x27;, &#x27;1520&#x27;, &#x27;1521&#x27;, &#x27;1522&#x27;, &#x27;1523&#x27;, &#x27;1524&#x27;, &#x27;1525&#x27;, &#x27;1526&#x27;, &#x27;1527&#x27;, &#x27;1528&#x27;, &#x27;1529&#x27;, &#x27;1530&#x27;, &#x27;1531&#x27;, &#x27;1532&#x27;, &#x27;1533&#x27;, &#x27;1534&#x27;, &#x27;1535&#x27;, &#x27;1536&#x27;, &#x27;1537&#x27;, &#x27;1538&#x27;, &#x27;1539&#x27;, &#x27;1540&#x27;, &#x27;1541&#x27;, &#x27;1542&#x27;, &#x27;1543&#x27;, &#x27;1544&#x27;, &#x27;1545&#x27;, &#x27;1546&#x27;, &#x27;1547&#x27;, &#x27;1548&#x27;, &#x27;1549&#x27;, &#x27;1550&#x27;, &#x27;1551&#x27;, &#x27;1552&#x27;, &#x27;1553&#x27;, &#x27;1554&#x27;, &#x27;1555&#x27;, &#x27;1556&#x27;, &#x27;1557&#x27;, &#x27;1558&#x27;, &#x27;1559&#x27;, &#x27;1560&#x27;, &#x27;1561&#x27;, &#x27;1562&#x27;, &#x27;1563&#x27;, &#x27;1564&#x27;, &#x27;1565&#x27;, &#x27;1566&#x27;, &#x27;1567&#x27;, &#x27;1568&#x27;, &#x27;1569&#x27;, &#x27;1570&#x27;, &#x27;1571&#x27;, &#x27;1572&#x27;, &#x27;1573&#x27;, &#x27;1574&#x27;, &#x27;1575&#x27;, &#x27;1576&#x27;, &#x27;1577&#x27;, &#x27;1578&#x27;, &#x27;1579&#x27;, &#x27;1580&#x27;, &#x27;1581&#x27;, &#x27;1582&#x27;, &#x27;1583&#x27;, &#x27;1584&#x27;, &#x27;1585&#x27;, &#x27;1586&#x27;, &#x27;1587&#x27;, &#x27;1588&#x27;, &#x27;1589&#x27;, &#x27;1590&#x27;, &#x27;1591&#x27;, &#x27;1592&#x27;, &#x27;1593&#x27;, &#x27;1594&#x27;, &#x27;1595&#x27;, &#x27;1596&#x27;, &#x27;1597&#x27;, &#x27;1598&#x27;, &#x27;1599&#x27;, &#x27;1600&#x27;, &#x27;1601&#x27;, &#x27;1602&#x27;, &#x27;1603&#x27;, &#x27;1604&#x27;, &#x27;1605&#x27;, &#x27;1606&#x27;, &#x27;1607&#x27;, &#x27;1608&#x27;, &#x27;1609&#x27;, &#x27;1610&#x27;, &#x27;1611&#x27;, &#x27;1612&#x27;, &#x27;1613&#x27;, &#x27;1614&#x27;, &#x27;1615&#x27;, &#x27;1616&#x27;, &#x27;1617&#x27;, &#x27;1618&#x27;, &#x27;1619&#x27;, &#x27;1620&#x27;, &#x27;1621&#x27;, &#x27;1622&#x27;, &#x27;1623&#x27;, &#x27;1624&#x27;, &#x27;1625&#x27;, &#x27;1626&#x27;, &#x27;1627&#x27;, &#x27;1628&#x27;, &#x27;1629&#x27;, &#x27;1630&#x27;, &#x27;1631&#x27;, &#x27;1632&#x27;, &#x27;1633&#x27;, &#x27;1634&#x27;, &#x27;1635&#x27;, &#x27;1636&#x27;, &#x27;1637&#x27;, &#x27;1638&#x27;, &#x27;1639&#x27;, &#x27;1640&#x27;, &#x27;1641&#x27;, &#x27;1642&#x27;, &#x27;1643&#x27;, &#x27;1644&#x27;, &#x27;1645&#x27;, &#x27;1646&#x27;, &#x27;1647&#x27;, &#x27;1648&#x27;, &#x27;1649&#x27;, &#x27;1650&#x27;, &#x27;1651&#x27;, &#x27;1652&#x27;, &#x27;1653&#x27;, &#x27;1654&#x27;, &#x27;1655&#x27;, &#x27;1656&#x27;, &#x27;1657&#x27;, &#x27;1658&#x27;, &#x27;1659&#x27;, &#x27;1660&#x27;, &#x27;1661&#x27;, &#x27;1662&#x27;, &#x27;1663&#x27;, &#x27;1664&#x27;, &#x27;1665&#x27;, &#x27;1666&#x27;, &#x27;1667&#x27;, &#x27;1668&#x27;, &#x27;1669&#x27;, &#x27;1670&#x27;, &#x27;1671&#x27;, &#x27;1672&#x27;, &#x27;1673&#x27;, &#x27;1674&#x27;, &#x27;1675&#x27;, &#x27;1676&#x27;, &#x27;1677&#x27;, &#x27;1678&#x27;, &#x27;1679&#x27;, &#x27;1680&#x27;, &#x27;1681&#x27;, &#x27;1682&#x27;, &#x27;1683&#x27;, &#x27;1684&#x27;, &#x27;1685&#x27;, &#x27;1686&#x27;, &#x27;1687&#x27;, &#x27;1688&#x27;, &#x27;1689&#x27;, &#x27;1690&#x27;, &#x27;1691&#x27;, &#x27;1692&#x27;, &#x27;1693&#x27;, &#x27;1694&#x27;, &#x27;1695&#x27;, &#x27;1696&#x27;, &#x27;1697&#x27;, &#x27;1698&#x27;, &#x27;1699&#x27;, &#x27;1700&#x27;, &#x27;1701&#x27;, &#x27;1702&#x27;, &#x27;1703&#x27;, &#x27;1704&#x27;, &#x27;1705&#x27;, &#x27;1706&#x27;, &#x27;1707&#x27;, &#x27;1708&#x27;, &#x27;1709&#x27;, &#x27;1710&#x27;, &#x27;1711&#x27;, &#x27;1712&#x27;, &#x27;1713&#x27;, &#x27;1714&#x27;, &#x27;1715&#x27;, &#x27;1716&#x27;, &#x27;1717&#x27;, &#x27;1718&#x27;, &#x27;1719&#x27;, &#x27;1720&#x27;, &#x27;1721&#x27;, &#x27;1722&#x27;, &#x27;1723&#x27;, &#x27;1724&#x27;, &#x27;1725&#x27;, &#x27;1726&#x27;, &#x27;1727&#x27;, &#x27;1728&#x27;, &#x27;1729&#x27;, &#x27;1730&#x27;, &#x27;1731&#x27;, &#x27;1732&#x27;, &#x27;1733&#x27;, &#x27;1734&#x27;, &#x27;1735&#x27;, &#x27;1736&#x27;, &#x27;1737&#x27;, &#x27;1738&#x27;, &#x27;1739&#x27;, &#x27;1740&#x27;, &#x27;1741&#x27;, &#x27;1742&#x27;, &#x27;1743&#x27;, &#x27;1744&#x27;, &#x27;1745&#x27;, &#x27;1746&#x27;, &#x27;1747&#x27;, &#x27;1748&#x27;, &#x27;1749&#x27;, &#x27;1750&#x27;, &#x27;1751&#x27;, &#x27;1752&#x27;, &#x27;1753&#x27;, &#x27;1754&#x27;, &#x27;1755&#x27;, &#x27;1756&#x27;, &#x27;1757&#x27;, &#x27;1758&#x27;, &#x27;1759&#x27;, &#x27;1760&#x27;, &#x27;1761&#x27;, &#x27;1762&#x27;, &#x27;1763&#x27;, &#x27;1764&#x27;, &#x27;1765&#x27;, &#x27;1766&#x27;, &#x27;1767&#x27;, &#x27;1768&#x27;, &#x27;1769&#x27;, &#x27;1770&#x27;, &#x27;1771&#x27;, &#x27;1772&#x27;, &#x27;1773&#x27;, &#x27;1774&#x27;, &#x27;1775&#x27;, &#x27;1776&#x27;, &#x27;1777&#x27;, &#x27;1778&#x27;, &#x27;1779&#x27;, &#x27;1780&#x27;, &#x27;1781&#x27;, &#x27;1782&#x27;, &#x27;1783&#x27;, &#x27;1784&#x27;, &#x27;1785&#x27;, &#x27;1786&#x27;, &#x27;1787&#x27;, &#x27;1788&#x27;, &#x27;1789&#x27;, &#x27;1790&#x27;, &#x27;1791&#x27;, &#x27;1792&#x27;, &#x27;1793&#x27;, &#x27;1794&#x27;, &#x27;1795&#x27;, &#x27;1796&#x27;, &#x27;1797&#x27;, &#x27;1798&#x27;, &#x27;1799&#x27;, &#x27;1800&#x27;, &#x27;1801&#x27;, &#x27;1802&#x27;, &#x27;1803&#x27;, &#x27;1804&#x27;, &#x27;1805&#x27;, &#x27;1806&#x27;, &#x27;1807&#x27;, &#x27;1808&#x27;, &#x27;1809&#x27;, &#x27;1810&#x27;, &#x27;1811&#x27;, &#x27;1812&#x27;, &#x27;1813&#x27;, &#x27;1814&#x27;, &#x27;1815&#x27;, &#x27;1816&#x27;, &#x27;1817&#x27;, &#x27;1818&#x27;, &#x27;1819&#x27;, &#x27;1820&#x27;, &#x27;1821&#x27;, &#x27;1822&#x27;, &#x27;1823&#x27;, &#x27;1824&#x27;, &#x27;1825&#x27;, &#x27;1826&#x27;, &#x27;1827&#x27;, &#x27;1828&#x27;, &#x27;1829&#x27;, &#x27;1830&#x27;, &#x27;1831&#x27;, &#x27;1832&#x27;, &#x27;1833&#x27;, &#x27;1834&#x27;, &#x27;1835&#x27;, &#x27;1836&#x27;, &#x27;1837&#x27;, &#x27;1838&#x27;, &#x27;1839&#x27;, &#x27;1840&#x27;, &#x27;1841&#x27;, &#x27;1842&#x27;, &#x27;1843&#x27;, &#x27;1844&#x27;, &#x27;1845&#x27;, &#x27;1846&#x27;, &#x27;1847&#x27;, &#x27;1848&#x27;, &#x27;1849&#x27;, &#x27;1850&#x27;, &#x27;1851&#x27;, &#x27;1852&#x27;, &#x27;1853&#x27;, &#x27;1854&#x27;, &#x27;1855&#x27;, &#x27;1856&#x27;, &#x27;1857&#x27;, &#x27;1858&#x27;, &#x27;1859&#x27;, &#x27;1860&#x27;, &#x27;1861&#x27;, &#x27;1862&#x27;, &#x27;1863&#x27;, &#x27;1864&#x27;, &#x27;1865&#x27;, &#x27;1866&#x27;, &#x27;1867&#x27;, &#x27;1868&#x27;, &#x27;1869&#x27;, &#x27;1870&#x27;, &#x27;1871&#x27;, &#x27;1872&#x27;, &#x27;1873&#x27;, &#x27;1874&#x27;, &#x27;1875&#x27;, &#x27;1876&#x27;, &#x27;1877&#x27;, &#x27;1878&#x27;, &#x27;1879&#x27;, &#x27;1880&#x27;, &#x27;1881&#x27;, &#x27;1882&#x27;, &#x27;1883&#x27;, &#x27;1884&#x27;, &#x27;1885&#x27;, &#x27;1886&#x27;, &#x27;1887&#x27;, &#x27;1888&#x27;, &#x27;1889&#x27;, &#x27;1890&#x27;, &#x27;1891&#x27;, &#x27;1892&#x27;, &#x27;1893&#x27;, &#x27;1894&#x27;, &#x27;1895&#x27;, &#x27;1896&#x27;, &#x27;1897&#x27;, &#x27;1898&#x27;, &#x27;1899&#x27;, &#x27;1900&#x27;, &#x27;1901&#x27;, &#x27;1902&#x27;, &#x27;1903&#x27;, &#x27;1904&#x27;, &#x27;1905&#x27;, &#x27;1906&#x27;, &#x27;1907&#x27;, &#x27;1908&#x27;, &#x27;1909&#x27;, &#x27;1910&#x27;, &#x27;1911&#x27;, &#x27;1912&#x27;, &#x27;1913&#x27;, &#x27;1914&#x27;, &#x27;1915&#x27;, &#x27;1916&#x27;, &#x27;1917&#x27;, &#x27;1918&#x27;, &#x27;1919&#x27;, &#x27;1920&#x27;, &#x27;1921&#x27;, &#x27;1922&#x27;, &#x27;1923&#x27;, &#x27;1924&#x27;, &#x27;1925&#x27;, &#x27;1926&#x27;, &#x27;1927&#x27;, &#x27;1928&#x27;, &#x27;1929&#x27;, &#x27;1930&#x27;, &#x27;1931&#x27;, &#x27;1932&#x27;, &#x27;1933&#x27;, &#x27;1934&#x27;, &#x27;1935&#x27;, &#x27;1936&#x27;, &#x27;1937&#x27;, &#x27;1938&#x27;, &#x27;1939&#x27;, &#x27;1940&#x27;, &#x27;1941&#x27;, &#x27;1942&#x27;, &#x27;1943&#x27;, &#x27;1944&#x27;, &#x27;1945&#x27;, &#x27;1946&#x27;, &#x27;1947&#x27;, &#x27;1948&#x27;, &#x27;1949&#x27;, &#x27;1950&#x27;, &#x27;1951&#x27;, &#x27;1952&#x27;, &#x27;1953&#x27;, &#x27;1954&#x27;, &#x27;1955&#x27;, &#x27;1956&#x27;, &#x27;1957&#x27;, &#x27;1958&#x27;, &#x27;1959&#x27;, &#x27;1960&#x27;, &#x27;1961&#x27;, &#x27;1962&#x27;, &#x27;1963&#x27;, &#x27;1964&#x27;, &#x27;1965&#x27;, &#x27;1966&#x27;, &#x27;1967&#x27;, &#x27;1968&#x27;, &#x27;1969&#x27;, &#x27;1970&#x27;, &#x27;1971&#x27;, &#x27;1972&#x27;, &#x27;1973&#x27;, &#x27;1974&#x27;, &#x27;1975&#x27;, &#x27;1976&#x27;, &#x27;1977&#x27;, &#x27;1978&#x27;, &#x27;1979&#x27;, &#x27;1980&#x27;, &#x27;1981&#x27;, &#x27;1982&#x27;, &#x27;1983&#x27;, &#x27;1984&#x27;, &#x27;1985&#x27;, &#x27;1986&#x27;, &#x27;1987&#x27;, &#x27;1988&#x27;, &#x27;1989&#x27;, &#x27;1990&#x27;, &#x27;1991&#x27;, &#x27;1992&#x27;, &#x27;1993&#x27;, &#x27;1994&#x27;, &#x27;1995&#x27;, &#x27;1996&#x27;, &#x27;1997&#x27;, &#x27;1998&#x27;, &#x27;1999&#x27;, &#x27;2000&#x27;, &#x27;2001&#x27;, &#x27;2002&#x27;, &#x27;2003&#x27;, &#x27;2004&#x27;, &#x27;2005&#x27;, &#x27;2006&#x27;, &#x27;2007&#x27;, &#x27;2008&#x27;, &#x27;2009&#x27;, &#x27;2010&#x27;, &#x27;2011&#x27;, &#x27;2012&#x27;, &#x27;2013&#x27;, &#x27;2014&#x27;, &#x27;2015&#x27;, &#x27;2016&#x27;, &#x27;2017&#x27;, &#x27;2018&#x27;, &#x27;2019&#x27;, &#x27;2020&#x27;, &#x27;2021&#x27;, &#x27;2022&#x27;, &#x27;2023&#x27;, &#x27;2024&#x27;, &#x27;2025&#x27;, &#x27;2026&#x27;, &#x27;2027&#x27;, &#x27;2028&#x27;, &#x27;2029&#x27;, &#x27;2030&#x27;, &#x27;2031&#x27;, &#x27;2032&#x27;, &#x27;2033&#x27;, &#x27;2034&#x27;, &#x27;2035&#x27;, &#x27;2036&#x27;, &#x27;2037&#x27;, &#x27;2038&#x27;, &#x27;2039&#x27;, &#x27;2040&#x27;, &#x27;2041&#x27;, &#x27;2042&#x27;, &#x27;2043&#x27;, &#x27;2044&#x27;, &#x27;2045&#x27;, &#x27;2046&#x27;, &#x27;2047&#x27;, &#x27;2048&#x27;, &#x27;2049&#x27;, &#x27;2050&#x27;, &#x27;2051&#x27;, &#x27;2052&#x27;, &#x27;2053&#x27;, &#x27;2054&#x27;, &#x27;2055&#x27;, &#x27;2056&#x27;, &#x27;2057&#x27;, &#x27;2058&#x27;, &#x27;2059&#x27;, &#x27;2060&#x27;, &#x27;2061&#x27;, &#x27;2062&#x27;, &#x27;2063&#x27;, &#x27;2064&#x27;, &#x27;2065&#x27;, &#x27;2066&#x27;, &#x27;2067&#x27;, &#x27;2068&#x27;, &#x27;2069&#x27;, &#x27;2070&#x27;, &#x27;2071&#x27;, &#x27;2072&#x27;, &#x27;2073&#x27;, &#x27;2074&#x27;, &#x27;2075&#x27;, &#x27;2076&#x27;, &#x27;2077&#x27;, &#x27;2078&#x27;, &#x27;2079&#x27;, &#x27;2080&#x27;, &#x27;2081&#x27;, &#x27;2082&#x27;, &#x27;2083&#x27;, &#x27;2084&#x27;, &#x27;2085&#x27;, &#x27;2086&#x27;, &#x27;2087&#x27;, &#x27;2088&#x27;, &#x27;2089&#x27;, &#x27;2090&#x27;, &#x27;2091&#x27;, &#x27;2092&#x27;, &#x27;2093&#x27;, &#x27;2094&#x27;, &#x27;2095&#x27;, &#x27;2096&#x27;, &#x27;2097&#x27;, &#x27;2098&#x27;, &#x27;2099&#x27;, &#x27;2100&#x27;, &#x27;2101&#x27;, &#x27;2102&#x27;, &#x27;2103&#x27;, &#x27;2104&#x27;, &#x27;2105&#x27;, &#x27;2106&#x27;, &#x27;2107&#x27;, &#x27;2108&#x27;, &#x27;2109&#x27;, &#x27;2110&#x27;, &#x27;2111&#x27;, &#x27;2112&#x27;, &#x27;2113&#x27;, &#x27;2114&#x27;, &#x27;2115&#x27;, &#x27;2116&#x27;, &#x27;2117&#x27;, &#x27;2118&#x27;, &#x27;2119&#x27;, &#x27;2120&#x27;, &#x27;2121&#x27;, &#x27;2122&#x27;, &#x27;2123&#x27;, &#x27;2124&#x27;, &#x27;2125&#x27;, &#x27;2126&#x27;, &#x27;2127&#x27;, &#x27;2128&#x27;, &#x27;2129&#x27;, &#x27;2130&#x27;, &#x27;2131&#x27;, &#x27;2132&#x27;, &#x27;2133&#x27;, &#x27;2134&#x27;, &#x27;2135&#x27;, &#x27;2136&#x27;, &#x27;2137&#x27;, &#x27;2138&#x27;, &#x27;2139&#x27;, &#x27;2140&#x27;, &#x27;2141&#x27;, &#x27;2142&#x27;, &#x27;2143&#x27;, &#x27;2144&#x27;, &#x27;2145&#x27;, &#x27;2146&#x27;, &#x27;2147&#x27;, &#x27;2148&#x27;, &#x27;2149&#x27;, &#x27;2150&#x27;, &#x27;2151&#x27;, &#x27;2152&#x27;, &#x27;2153&#x27;, &#x27;2154&#x27;, &#x27;2155&#x27;, &#x27;2156&#x27;, &#x27;2157&#x27;, &#x27;2158&#x27;, &#x27;2159&#x27;, &#x27;2160&#x27;, &#x27;2161&#x27;, &#x27;2162&#x27;, &#x27;2163&#x27;, &#x27;2164&#x27;, &#x27;2165&#x27;, &#x27;2166&#x27;, &#x27;2167&#x27;, &#x27;2168&#x27;, &#x27;2169&#x27;, &#x27;2170&#x27;, &#x27;2171&#x27;, &#x27;2172&#x27;, &#x27;2173&#x27;, &#x27;2174&#x27;, &#x27;2175&#x27;, &#x27;2176&#x27;, &#x27;2177&#x27;, &#x27;2178&#x27;, &#x27;2179&#x27;, &#x27;2180&#x27;, &#x27;2181&#x27;, &#x27;2182&#x27;, &#x27;2183&#x27;, &#x27;2184&#x27;, &#x27;2185&#x27;, &#x27;2186&#x27;, &#x27;2187&#x27;, &#x27;2188&#x27;, &#x27;2189&#x27;, &#x27;2190&#x27;, &#x27;2191&#x27;, &#x27;2192&#x27;, &#x27;2193&#x27;, &#x27;2194&#x27;, &#x27;2195&#x27;, &#x27;2196&#x27;, &#x27;2197&#x27;, &#x27;2198&#x27;, &#x27;2199&#x27;, &#x27;2200&#x27;, &#x27;2201&#x27;, &#x27;2202&#x27;, &#x27;2203&#x27;, &#x27;2204&#x27;, &#x27;2205&#x27;, &#x27;2206&#x27;, &#x27;2207&#x27;, &#x27;2208&#x27;, &#x27;2209&#x27;, &#x27;2210&#x27;, &#x27;2211&#x27;, &#x27;2212&#x27;, &#x27;2213&#x27;, &#x27;2214&#x27;, &#x27;2215&#x27;, &#x27;2216&#x27;, &#x27;2217&#x27;, &#x27;2218&#x27;, &#x27;2219&#x27;, &#x27;2220&#x27;, &#x27;2221&#x27;, &#x27;2222&#x27;, &#x27;2223&#x27;, &#x27;2224&#x27;, &#x27;2225&#x27;, &#x27;2226&#x27;, &#x27;2227&#x27;, &#x27;2228&#x27;, &#x27;2229&#x27;, &#x27;2230&#x27;, &#x27;2231&#x27;, &#x27;2232&#x27;, &#x27;2233&#x27;, &#x27;2234&#x27;, &#x27;2235&#x27;, &#x27;2236&#x27;, &#x27;2237&#x27;, &#x27;2238&#x27;, &#x27;2239&#x27;, &#x27;2240&#x27;, &#x27;2241&#x27;, &#x27;2242&#x27;, &#x27;2243&#x27;, &#x27;2244&#x27;, &#x27;2245&#x27;, &#x27;2246&#x27;, &#x27;2247&#x27;, &#x27;2248&#x27;, &#x27;2249&#x27;, &#x27;2250&#x27;, &#x27;2251&#x27;, &#x27;2252&#x27;, &#x27;2253&#x27;, &#x27;2254&#x27;, &#x27;2255&#x27;, &#x27;2256&#x27;, &#x27;2257&#x27;, &#x27;2258&#x27;, &#x27;2259&#x27;, &#x27;2260&#x27;, &#x27;2261&#x27;, &#x27;2262&#x27;, &#x27;2263&#x27;, &#x27;2264&#x27;, &#x27;2265&#x27;, &#x27;2266&#x27;, &#x27;2267&#x27;, &#x27;2268&#x27;, &#x27;2269&#x27;, &#x27;2270&#x27;, &#x27;2271&#x27;, &#x27;2272&#x27;, &#x27;2273&#x27;, &#x27;2274&#x27;, &#x27;2275&#x27;, &#x27;2276&#x27;, &#x27;2277&#x27;, &#x27;2278&#x27;, &#x27;2279&#x27;, &#x27;2280&#x27;, &#x27;2281&#x27;, &#x27;2282&#x27;, &#x27;2283&#x27;, &#x27;2284&#x27;, &#x27;2285&#x27;, &#x27;2286&#x27;, &#x27;2287&#x27;, &#x27;2288&#x27;, &#x27;2289&#x27;, &#x27;2290&#x27;, &#x27;2291&#x27;, &#x27;2292&#x27;, &#x27;2293&#x27;, &#x27;2294&#x27;, &#x27;2295&#x27;, &#x27;2296&#x27;, &#x27;2297&#x27;, &#x27;2298&#x27;, &#x27;2299&#x27;, &#x27;2300&#x27;, &#x27;2301&#x27;, &#x27;2302&#x27;, &#x27;2303&#x27;, &#x27;2304&#x27;, &#x27;2305&#x27;, &#x27;2306&#x27;, &#x27;2307&#x27;, &#x27;2308&#x27;, &#x27;2309&#x27;, &#x27;2310&#x27;, &#x27;2311&#x27;, &#x27;2312&#x27;, &#x27;2313&#x27;, &#x27;2314&#x27;, &#x27;2315&#x27;, &#x27;2316&#x27;, &#x27;2317&#x27;, &#x27;2318&#x27;, &#x27;2319&#x27;, &#x27;2320&#x27;, &#x27;2321&#x27;, &#x27;2322&#x27;, &#x27;2323&#x27;, &#x27;2324&#x27;, &#x27;2325&#x27;, &#x27;2326&#x27;, &#x27;2327&#x27;, &#x27;2328&#x27;, &#x27;2329&#x27;, &#x27;2330&#x27;, &#x27;2331&#x27;, &#x27;2332&#x27;, &#x27;2333&#x27;, &#x27;2334&#x27;, &#x27;2335&#x27;, &#x27;2336&#x27;, &#x27;2337&#x27;, &#x27;2338&#x27;, &#x27;2339&#x27;, &#x27;2340&#x27;, &#x27;2341&#x27;, &#x27;2342&#x27;, &#x27;2343&#x27;, &#x27;2344&#x27;, &#x27;2345&#x27;, &#x27;2346&#x27;, &#x27;2347&#x27;, &#x27;2348&#x27;, &#x27;2349&#x27;, &#x27;2350&#x27;, &#x27;2351&#x27;, &#x27;2352&#x27;, &#x27;2353&#x27;, &#x27;2354&#x27;, &#x27;2355&#x27;, &#x27;2356&#x27;, &#x27;2357&#x27;, &#x27;2358&#x27;, &#x27;2359&#x27;, &#x27;2360&#x27;, &#x27;2361&#x27;, &#x27;2362&#x27;, &#x27;2363&#x27;, &#x27;2364&#x27;, &#x27;2365&#x27;, &#x27;2366&#x27;, &#x27;2367&#x27;, &#x27;2368&#x27;, &#x27;2369&#x27;, &#x27;2370&#x27;, &#x27;2371&#x27;, &#x27;2372&#x27;, &#x27;2373&#x27;, &#x27;2374&#x27;, &#x27;2375&#x27;, &#x27;2376&#x27;, &#x27;2377&#x27;, &#x27;2378&#x27;, &#x27;2379&#x27;, &#x27;2380&#x27;, &#x27;2381&#x27;, &#x27;2382&#x27;, &#x27;2383&#x27;, &#x27;2384&#x27;, &#x27;2385&#x27;, &#x27;2386&#x27;, &#x27;2387&#x27;, &#x27;2388&#x27;, &#x27;2389&#x27;, &#x27;2390&#x27;, &#x27;2391&#x27;, &#x27;2392&#x27;, &#x27;2393&#x27;, &#x27;2394&#x27;, &#x27;2395&#x27;, &#x27;2396&#x27;, &#x27;2397&#x27;, &#x27;2398&#x27;, &#x27;2399&#x27;, &#x27;2400&#x27;, &#x27;2401&#x27;, &#x27;2402&#x27;, &#x27;2403&#x27;, &#x27;2404&#x27;, &#x27;2405&#x27;, &#x27;2406&#x27;, &#x27;2407&#x27;, &#x27;2408&#x27;, &#x27;2409&#x27;, &#x27;2410&#x27;, &#x27;2411&#x27;, &#x27;2412&#x27;, &#x27;2413&#x27;, &#x27;2414&#x27;, &#x27;2415&#x27;, &#x27;2416&#x27;, &#x27;2417&#x27;, &#x27;2418&#x27;, &#x27;2419&#x27;, &#x27;2420&#x27;, &#x27;2421&#x27;, &#x27;2422&#x27;, &#x27;2423&#x27;, &#x27;2424&#x27;, &#x27;2425&#x27;, &#x27;2426&#x27;, &#x27;2427&#x27;, &#x27;2428&#x27;, &#x27;2429&#x27;, &#x27;2430&#x27;, &#x27;2431&#x27;, &#x27;2432&#x27;, &#x27;2433&#x27;, &#x27;2434&#x27;, &#x27;2435&#x27;, &#x27;2436&#x27;, &#x27;2437&#x27;, &#x27;2438&#x27;, &#x27;2439&#x27;, &#x27;2440&#x27;, &#x27;2441&#x27;, &#x27;2442&#x27;, &#x27;2443&#x27;, &#x27;2444&#x27;, &#x27;2445&#x27;, &#x27;2446&#x27;, &#x27;2447&#x27;, &#x27;2448&#x27;, &#x27;2449&#x27;, &#x27;2450&#x27;, &#x27;2451&#x27;, &#x27;2452&#x27;, &#x27;2453&#x27;, &#x27;2454&#x27;, &#x27;2455&#x27;, &#x27;2456&#x27;, &#x27;2457&#x27;, &#x27;2458&#x27;, &#x27;2459&#x27;, &#x27;2460&#x27;, &#x27;2461&#x27;, &#x27;2462&#x27;, &#x27;2463&#x27;, &#x27;2464&#x27;, &#x27;2465&#x27;, &#x27;2466&#x27;, &#x27;2467&#x27;, &#x27;2468&#x27;, &#x27;2469&#x27;, &#x27;2470&#x27;, &#x27;2471&#x27;, &#x27;2472&#x27;, &#x27;2473&#x27;, &#x27;2474&#x27;, &#x27;2475&#x27;, &#x27;2476&#x27;, &#x27;2477&#x27;, &#x27;2478&#x27;, &#x27;2479&#x27;, &#x27;2480&#x27;, &#x27;2481&#x27;, &#x27;2482&#x27;, &#x27;2483&#x27;, &#x27;2484&#x27;, &#x27;2485&#x27;, &#x27;2486&#x27;, &#x27;2487&#x27;, &#x27;2488&#x27;, &#x27;2489&#x27;, &#x27;2490&#x27;, &#x27;2491&#x27;, &#x27;2492&#x27;, &#x27;2493&#x27;, &#x27;2494&#x27;, &#x27;2495&#x27;, &#x27;2496&#x27;, &#x27;2497&#x27;, &#x27;2498&#x27;, &#x27;2499&#x27;, &#x27;2500&#x27;, &#x27;2501&#x27;, &#x27;2502&#x27;, &#x27;2503&#x27;, &#x27;2504&#x27;, &#x27;2505&#x27;, &#x27;2506&#x27;, &#x27;2507&#x27;, &#x27;2508&#x27;, &#x27;2509&#x27;, &#x27;2510&#x27;, &#x27;2511&#x27;, &#x27;2512&#x27;, &#x27;2513&#x27;, &#x27;2514&#x27;, &#x27;2515&#x27;, &#x27;2516&#x27;, &#x27;2517&#x27;, &#x27;2518&#x27;, &#x27;2519&#x27;, &#x27;2520&#x27;, &#x27;2521&#x27;, &#x27;2522&#x27;, &#x27;2523&#x27;, &#x27;2524&#x27;, &#x27;2525&#x27;, &#x27;2526&#x27;, &#x27;2527&#x27;, &#x27;2528&#x27;, &#x27;2529&#x27;, &#x27;2530&#x27;, &#x27;2531&#x27;, &#x27;2532&#x27;, &#x27;2533&#x27;, &#x27;2534&#x27;, &#x27;2535&#x27;, &#x27;2536&#x27;, &#x27;2537&#x27;, &#x27;2538&#x27;, &#x27;2539&#x27;, &#x27;2540&#x27;, &#x27;2541&#x27;, &#x27;2542&#x27;, &#x27;2543&#x27;, &#x27;2544&#x27;, &#x27;2545&#x27;, &#x27;2546&#x27;, &#x27;2547&#x27;, &#x27;2548&#x27;, &#x27;2549&#x27;, &#x27;2550&#x27;, &#x27;2551&#x27;, &#x27;2552&#x27;, &#x27;2553&#x27;, &#x27;2554&#x27;, &#x27;2555&#x27;, &#x27;2556&#x27;, &#x27;2557&#x27;, &#x27;2558&#x27;, &#x27;2559&#x27;, &#x27;2560&#x27;, &#x27;2561&#x27;, &#x27;2562&#x27;, &#x27;2563&#x27;, &#x27;2564&#x27;, &#x27;2565&#x27;, &#x27;2566&#x27;, &#x27;2567&#x27;, &#x27;2568&#x27;, &#x27;2569&#x27;, &#x27;2570&#x27;, &#x27;2571&#x27;, &#x27;2572&#x27;, &#x27;2573&#x27;, &#x27;2574&#x27;, &#x27;2575&#x27;, &#x27;2576&#x27;, &#x27;2577&#x27;, &#x27;2578&#x27;, &#x27;2579&#x27;, &#x27;2580&#x27;, &#x27;2581&#x27;, &#x27;2582&#x27;, &#x27;2583&#x27;, &#x27;2584&#x27;, &#x27;2585&#x27;, &#x27;2586&#x27;, &#x27;2587&#x27;, &#x27;2588&#x27;, &#x27;2589&#x27;, &#x27;2590&#x27;, &#x27;2591&#x27;, &#x27;2592&#x27;, &#x27;2593&#x27;, &#x27;2594&#x27;, &#x27;2595&#x27;, &#x27;2596&#x27;, &#x27;2597&#x27;, &#x27;2598&#x27;, &#x27;2599&#x27;, &#x27;2600&#x27;, &#x27;2601&#x27;, &#x27;2602&#x27;, &#x27;2603&#x27;, &#x27;2604&#x27;, &#x27;2605&#x27;, &#x27;2606&#x27;, &#x27;2607&#x27;, &#x27;2608&#x27;, &#x27;2609&#x27;, &#x27;2610&#x27;, &#x27;2611&#x27;, &#x27;2612&#x27;, &#x27;2613&#x27;, &#x27;2614&#x27;, &#x27;2615&#x27;, &#x27;2616&#x27;, &#x27;2617&#x27;, &#x27;2618&#x27;, &#x27;2619&#x27;, &#x27;2620&#x27;, &#x27;2621&#x27;, &#x27;2622&#x27;, &#x27;2623&#x27;, &#x27;2624&#x27;, &#x27;2625&#x27;, &#x27;2626&#x27;, &#x27;2627&#x27;, &#x27;2628&#x27;, &#x27;2629&#x27;, &#x27;2630&#x27;, &#x27;2631&#x27;, &#x27;2632&#x27;, &#x27;2633&#x27;, &#x27;2634&#x27;, &#x27;2635&#x27;, &#x27;2636&#x27;, &#x27;2637&#x27;, &#x27;2638&#x27;, &#x27;2639&#x27;, &#x27;2640&#x27;, &#x27;2641&#x27;, &#x27;2642&#x27;, &#x27;2643&#x27;, &#x27;2644&#x27;, &#x27;2645&#x27;, &#x27;2646&#x27;, &#x27;2647&#x27;, &#x27;2648&#x27;, &#x27;2649&#x27;, &#x27;2650&#x27;, &#x27;2651&#x27;, &#x27;2652&#x27;, &#x27;2653&#x27;, &#x27;2654&#x27;, &#x27;2655&#x27;, &#x27;2656&#x27;, &#x27;2657&#x27;, &#x27;2658&#x27;, &#x27;2659&#x27;, &#x27;2660&#x27;, &#x27;2661&#x27;, &#x27;2662&#x27;, &#x27;2663&#x27;, &#x27;2664&#x27;, &#x27;2665&#x27;, &#x27;2666&#x27;, &#x27;2667&#x27;, &#x27;2668&#x27;, &#x27;2669&#x27;, &#x27;2670&#x27;, &#x27;2671&#x27;, &#x27;2672&#x27;, &#x27;2673&#x27;, &#x27;2674&#x27;, &#x27;2675&#x27;, &#x27;2676&#x27;, &#x27;2677&#x27;, &#x27;2678&#x27;, &#x27;2679&#x27;, &#x27;2680&#x27;, &#x27;2681&#x27;, &#x27;2682&#x27;, &#x27;2683&#x27;, &#x27;2684&#x27;, &#x27;2685&#x27;, &#x27;2686&#x27;, &#x27;2687&#x27;, &#x27;2688&#x27;, &#x27;2689&#x27;, &#x27;2690&#x27;, &#x27;2691&#x27;, &#x27;2692&#x27;, &#x27;2693&#x27;, &#x27;2694&#x27;, &#x27;2695&#x27;, &#x27;2696&#x27;, &#x27;2697&#x27;, &#x27;2698&#x27;, &#x27;2699&#x27;, &#x27;2700&#x27;, &#x27;2701&#x27;, &#x27;2702&#x27;, &#x27;2703&#x27;, &#x27;2704&#x27;, &#x27;2705&#x27;, &#x27;2706&#x27;, &#x27;2707&#x27;, &#x27;2708&#x27;, &#x27;2709&#x27;, &#x27;2710&#x27;, &#x27;2711&#x27;, &#x27;2712&#x27;, &#x27;2713&#x27;, &#x27;2714&#x27;, &#x27;2715&#x27;, &#x27;2716&#x27;, &#x27;2717&#x27;, &#x27;2718&#x27;, &#x27;2719&#x27;, &#x27;2720&#x27;, &#x27;2721&#x27;, &#x27;2722&#x27;, &#x27;2723&#x27;, &#x27;2724&#x27;, &#x27;2725&#x27;, &#x27;2726&#x27;, &#x27;2727&#x27;, &#x27;2728&#x27;, &#x27;2729&#x27;, &#x27;2730&#x27;, &#x27;2731&#x27;, &#x27;2732&#x27;, &#x27;2733&#x27;, &#x27;2734&#x27;, &#x27;2735&#x27;, &#x27;2736&#x27;, &#x27;2737&#x27;, &#x27;2738&#x27;, &#x27;2739&#x27;, &#x27;2740&#x27;, &#x27;2741&#x27;, &#x27;2742&#x27;, &#x27;2743&#x27;, &#x27;2744&#x27;, &#x27;2745&#x27;, &#x27;2746&#x27;, &#x27;2747&#x27;, &#x27;2748&#x27;, &#x27;2749&#x27;, &#x27;2750&#x27;, &#x27;2751&#x27;, &#x27;2752&#x27;, &#x27;2753&#x27;, &#x27;2754&#x27;, &#x27;2755&#x27;, &#x27;2756&#x27;, &#x27;2757&#x27;, &#x27;2758&#x27;, &#x27;2759&#x27;, &#x27;2760&#x27;, &#x27;2761&#x27;, &#x27;2762&#x27;, &#x27;2763&#x27;, &#x27;2764&#x27;, &#x27;2765&#x27;, &#x27;2766&#x27;, &#x27;2767&#x27;, &#x27;2768&#x27;, &#x27;2769&#x27;, &#x27;2770&#x27;, &#x27;2771&#x27;, &#x27;2772&#x27;, &#x27;2773&#x27;, &#x27;2774&#x27;, &#x27;2775&#x27;, &#x27;2776&#x27;, &#x27;2777&#x27;, &#x27;2778&#x27;, &#x27;2779&#x27;, &#x27;2780&#x27;, &#x27;2781&#x27;, &#x27;2782&#x27;, &#x27;2783&#x27;, &#x27;2784&#x27;, &#x27;2785&#x27;, &#x27;2786&#x27;, &#x27;2787&#x27;, &#x27;2788&#x27;, &#x27;2789&#x27;, &#x27;2790&#x27;, &#x27;2791&#x27;, &#x27;2792&#x27;, &#x27;2793&#x27;, &#x27;2794&#x27;, &#x27;2795&#x27;, &#x27;2796&#x27;, &#x27;2797&#x27;, &#x27;2798&#x27;, &#x27;2799&#x27;, &#x27;2800&#x27;, &#x27;2801&#x27;, &#x27;2802&#x27;, &#x27;2803&#x27;, &#x27;2804&#x27;, &#x27;2805&#x27;, &#x27;2806&#x27;, &#x27;2807&#x27;, &#x27;2808&#x27;, &#x27;2809&#x27;, &#x27;2810&#x27;, &#x27;2811&#x27;, &#x27;2812&#x27;, &#x27;2813&#x27;, &#x27;2814&#x27;, &#x27;2815&#x27;, &#x27;2816&#x27;, &#x27;2817&#x27;, &#x27;2818&#x27;, &#x27;2819&#x27;, &#x27;2820&#x27;, &#x27;2821&#x27;, &#x27;2822&#x27;, &#x27;2823&#x27;, &#x27;2824&#x27;, &#x27;2825&#x27;, &#x27;2826&#x27;, &#x27;2827&#x27;, &#x27;2828&#x27;, &#x27;2829&#x27;, &#x27;2830&#x27;, &#x27;2831&#x27;, &#x27;2832&#x27;, &#x27;2833&#x27;, &#x27;2834&#x27;, &#x27;2835&#x27;, &#x27;2836&#x27;, &#x27;2837&#x27;, &#x27;2838&#x27;, &#x27;2839&#x27;, &#x27;2840&#x27;, &#x27;2841&#x27;, &#x27;2842&#x27;, &#x27;2843&#x27;, &#x27;2844&#x27;, &#x27;2845&#x27;, &#x27;2846&#x27;, &#x27;2847&#x27;, &#x27;2848&#x27;, &#x27;2849&#x27;, &#x27;2850&#x27;, &#x27;2851&#x27;, &#x27;2852&#x27;, &#x27;2853&#x27;, &#x27;2854&#x27;, &#x27;2855&#x27;, &#x27;2856&#x27;, &#x27;2857&#x27;, &#x27;2858&#x27;, &#x27;2859&#x27;, &#x27;2860&#x27;, &#x27;2861&#x27;, &#x27;2862&#x27;, &#x27;2863&#x27;, &#x27;2864&#x27;, &#x27;2865&#x27;, &#x27;2866&#x27;, &#x27;2867&#x27;, &#x27;2868&#x27;, &#x27;2869&#x27;, &#x27;2870&#x27;, &#x27;2871&#x27;, &#x27;2872&#x27;, &#x27;2873&#x27;, &#x27;2874&#x27;, &#x27;2875&#x27;, &#x27;2876&#x27;, &#x27;2877&#x27;, &#x27;2878&#x27;, &#x27;2879&#x27;, &#x27;2880&#x27;, &#x27;2881&#x27;, &#x27;2882&#x27;, &#x27;2883&#x27;, &#x27;2884&#x27;, &#x27;2885&#x27;, &#x27;2886&#x27;, &#x27;2887&#x27;, &#x27;2888&#x27;, &#x27;2889&#x27;, &#x27;2890&#x27;, &#x27;2891&#x27;, &#x27;2892&#x27;, &#x27;2893&#x27;, &#x27;2894&#x27;, &#x27;2895&#x27;, &#x27;2896&#x27;, &#x27;2897&#x27;, &#x27;2898&#x27;, &#x27;2899&#x27;, &#x27;2900&#x27;, &#x27;2901&#x27;, &#x27;2902&#x27;, &#x27;2903&#x27;, &#x27;2904&#x27;, &#x27;2905&#x27;, &#x27;2906&#x27;, &#x27;2907&#x27;, &#x27;2908&#x27;, &#x27;2909&#x27;, &#x27;2910&#x27;, &#x27;2911&#x27;, &#x27;2912&#x27;, &#x27;2913&#x27;, &#x27;2914&#x27;, &#x27;2915&#x27;, &#x27;2916&#x27;, &#x27;2917&#x27;, &#x27;2918&#x27;, &#x27;2919&#x27;, &#x27;2920&#x27;, &#x27;2921&#x27;, &#x27;2922&#x27;, &#x27;2923&#x27;, &#x27;2924&#x27;, &#x27;2925&#x27;, &#x27;2926&#x27;, &#x27;2927&#x27;, &#x27;2928&#x27;, &#x27;2929&#x27;, &#x27;2930&#x27;, &#x27;2931&#x27;, &#x27;2932&#x27;, &#x27;2933&#x27;, &#x27;2934&#x27;, &#x27;2935&#x27;, &#x27;2936&#x27;, &#x27;2937&#x27;, &#x27;2938&#x27;, &#x27;2939&#x27;, &#x27;2940&#x27;, &#x27;2941&#x27;, &#x27;2942&#x27;, &#x27;2943&#x27;, &#x27;2944&#x27;, &#x27;2945&#x27;, &#x27;2946&#x27;, &#x27;2947&#x27;, &#x27;2948&#x27;, &#x27;2949&#x27;, &#x27;2950&#x27;, &#x27;2951&#x27;, &#x27;2952&#x27;, &#x27;2953&#x27;, &#x27;2954&#x27;, &#x27;2955&#x27;, &#x27;2956&#x27;, &#x27;2957&#x27;, &#x27;2958&#x27;, &#x27;2959&#x27;, &#x27;2960&#x27;, &#x27;2961&#x27;, &#x27;2962&#x27;, &#x27;2963&#x27;, &#x27;2964&#x27;, &#x27;2965&#x27;, &#x27;2966&#x27;, &#x27;2967&#x27;, &#x27;2968&#x27;, &#x27;2969&#x27;, &#x27;2970&#x27;, &#x27;2971&#x27;, &#x27;2972&#x27;, &#x27;2973&#x27;, &#x27;2974&#x27;, &#x27;2975&#x27;, &#x27;2976&#x27;, &#x27;2977&#x27;, &#x27;2978&#x27;, &#x27;2979&#x27;, &#x27;2980&#x27;, &#x27;2981&#x27;, &#x27;2982&#x27;, &#x27;2983&#x27;, &#x27;2984&#x27;, &#x27;2985&#x27;, &#x27;2986&#x27;, &#x27;2987&#x27;, &#x27;2988&#x27;, &#x27;2989&#x27;, &#x27;2990&#x27;, &#x27;2991&#x27;, &#x27;2992&#x27;, &#x27;2993&#x27;, &#x27;2994&#x27;, &#x27;2995&#x27;, &#x27;2996&#x27;, &#x27;2997&#x27;, &#x27;2998&#x27;, &#x27;2999&#x27;, &#x27;3000&#x27;, &#x27;3001&#x27;, &#x27;3002&#x27;, &#x27;3003&#x27;, &#x27;3004&#x27;, &#x27;3005&#x27;, &#x27;3006&#x27;, &#x27;3007&#x27;, &#x27;3008&#x27;, &#x27;3009&#x27;, &#x27;3010&#x27;, &#x27;3011&#x27;, &#x27;3012&#x27;, &#x27;3013&#x27;, &#x27;3014&#x27;, &#x27;3015&#x27;, &#x27;3016&#x27;, &#x27;3017&#x27;, &#x27;3018&#x27;, &#x27;3019&#x27;, &#x27;3020&#x27;, &#x27;3021&#x27;, &#x27;3022&#x27;, &#x27;3023&#x27;, &#x27;3024&#x27;, &#x27;3025&#x27;, &#x27;3026&#x27;, &#x27;3027&#x27;, &#x27;3028&#x27;, &#x27;3029&#x27;, &#x27;3030&#x27;, &#x27;3031&#x27;, &#x27;3032&#x27;, &#x27;3033&#x27;, &#x27;3034&#x27;, &#x27;3035&#x27;, &#x27;3036&#x27;, &#x27;3037&#x27;, &#x27;3038&#x27;, &#x27;3039&#x27;, &#x27;3040&#x27;, &#x27;3041&#x27;, &#x27;3042&#x27;, &#x27;3043&#x27;, &#x27;3044&#x27;, &#x27;3045&#x27;, &#x27;3046&#x27;, &#x27;3047&#x27;, &#x27;3048&#x27;, &#x27;3049&#x27;, &#x27;3050&#x27;, &#x27;3051&#x27;, &#x27;3052&#x27;, &#x27;3053&#x27;, &#x27;3054&#x27;, &#x27;3055&#x27;, &#x27;3056&#x27;, &#x27;3057&#x27;, &#x27;3058&#x27;, &#x27;3059&#x27;, &#x27;3060&#x27;, &#x27;3061&#x27;, &#x27;3062&#x27;, &#x27;3063&#x27;, &#x27;3064&#x27;, &#x27;3065&#x27;, &#x27;3066&#x27;, &#x27;3067&#x27;, &#x27;3068&#x27;, &#x27;3069&#x27;, &#x27;3070&#x27;, &#x27;3071&#x27;, &#x27;3072&#x27;, &#x27;3073&#x27;, &#x27;3074&#x27;, &#x27;3075&#x27;, &#x27;3076&#x27;, &#x27;3077&#x27;, &#x27;3078&#x27;, &#x27;3079&#x27;, &#x27;3080&#x27;, &#x27;3081&#x27;, &#x27;3082&#x27;, &#x27;3083&#x27;, &#x27;3084&#x27;, &#x27;3085&#x27;, &#x27;3086&#x27;, &#x27;3087&#x27;, &#x27;3088&#x27;, &#x27;3089&#x27;, &#x27;3090&#x27;, &#x27;3091&#x27;, &#x27;3092&#x27;, &#x27;3093&#x27;, &#x27;3094&#x27;, &#x27;3095&#x27;, &#x27;3096&#x27;, &#x27;3097&#x27;, &#x27;3098&#x27;, &#x27;3099&#x27;, &#x27;3100&#x27;, &#x27;3101&#x27;, &#x27;3102&#x27;, &#x27;3103&#x27;, &#x27;3104&#x27;, &#x27;3105&#x27;, &#x27;3106&#x27;, &#x27;3107&#x27;, &#x27;3108&#x27;, &#x27;3109&#x27;, &#x27;3110&#x27;, &#x27;3111&#x27;, &#x27;3112&#x27;, &#x27;3113&#x27;, &#x27;3114&#x27;, &#x27;3115&#x27;, &#x27;3116&#x27;, &#x27;3117&#x27;, &#x27;3118&#x27;, &#x27;3119&#x27;, &#x27;3120&#x27;, &#x27;3121&#x27;, &#x27;3122&#x27;, &#x27;3123&#x27;, &#x27;3124&#x27;, &#x27;3125&#x27;, &#x27;3126&#x27;, &#x27;3127&#x27;, &#x27;3128&#x27;, &#x27;3129&#x27;, &#x27;3130&#x27;, &#x27;3131&#x27;, &#x27;3132&#x27;, &#x27;3133&#x27;, &#x27;3134&#x27;, &#x27;3135&#x27;, &#x27;3136&#x27;, &#x27;3137&#x27;, &#x27;3138&#x27;, &#x27;3139&#x27;, &#x27;3140&#x27;, &#x27;3141&#x27;, &#x27;3142&#x27;, &#x27;3143&#x27;, &#x27;3144&#x27;, &#x27;3145&#x27;, &#x27;3146&#x27;, &#x27;3147&#x27;, &#x27;3148&#x27;, &#x27;3149&#x27;, &#x27;3150&#x27;, &#x27;3151&#x27;, &#x27;3152&#x27;, &#x27;3153&#x27;, &#x27;3154&#x27;, &#x27;3155&#x27;, &#x27;3156&#x27;, &#x27;3157&#x27;, &#x27;3158&#x27;, &#x27;3159&#x27;, &#x27;3160&#x27;, &#x27;3161&#x27;, &#x27;3162&#x27;, &#x27;3163&#x27;, &#x27;3164&#x27;, &#x27;3165&#x27;, &#x27;3166&#x27;, &#x27;3167&#x27;, &#x27;3168&#x27;, &#x27;3169&#x27;, &#x27;3170&#x27;, &#x27;3171&#x27;, &#x27;3172&#x27;, &#x27;3173&#x27;, &#x27;3174&#x27;, &#x27;3175&#x27;, &#x27;3176&#x27;, &#x27;3177&#x27;, &#x27;3178&#x27;, &#x27;3179&#x27;, &#x27;3180&#x27;, &#x27;3181&#x27;, &#x27;3182&#x27;, &#x27;3183&#x27;, &#x27;3184&#x27;, &#x27;3185&#x27;, &#x27;3186&#x27;, &#x27;3187&#x27;, &#x27;3188&#x27;, &#x27;3189&#x27;, &#x27;3190&#x27;, &#x27;3191&#x27;, &#x27;3192&#x27;, &#x27;3193&#x27;, &#x27;3194&#x27;, &#x27;3195&#x27;, &#x27;3196&#x27;, &#x27;3197&#x27;, &#x27;3198&#x27;, &#x27;3199&#x27;, &#x27;3200&#x27;, &#x27;3201&#x27;, &#x27;3202&#x27;, &#x27;3203&#x27;, &#x27;3204&#x27;, &#x27;3205&#x27;, &#x27;3206&#x27;, &#x27;3207&#x27;, &#x27;3208&#x27;, &#x27;3209&#x27;, &#x27;3210&#x27;, &#x27;3211&#x27;, &#x27;3212&#x27;, &#x27;3213&#x27;, &#x27;3214&#x27;, &#x27;3215&#x27;, &#x27;3216&#x27;, &#x27;3217&#x27;, &#x27;3218&#x27;, &#x27;3219&#x27;, &#x27;3220&#x27;, &#x27;3221&#x27;, &#x27;3222&#x27;, &#x27;3223&#x27;, &#x27;3224&#x27;, &#x27;3225&#x27;, &#x27;3226&#x27;, &#x27;3227&#x27;, &#x27;3228&#x27;, &#x27;3229&#x27;, &#x27;3230&#x27;, &#x27;3231&#x27;, &#x27;3232&#x27;, &#x27;3233&#x27;, &#x27;3234&#x27;, &#x27;3235&#x27;, &#x27;3236&#x27;, &#x27;3237&#x27;, &#x27;3238&#x27;, &#x27;3239&#x27;, &#x27;3240&#x27;, &#x27;3241&#x27;, &#x27;3242&#x27;, &#x27;3243&#x27;, &#x27;3244&#x27;, &#x27;3245&#x27;, &#x27;3246&#x27;, &#x27;3247&#x27;, &#x27;3248&#x27;, &#x27;3249&#x27;, &#x27;3250&#x27;, &#x27;3251&#x27;, &#x27;3252&#x27;, &#x27;3253&#x27;, &#x27;3254&#x27;, &#x27;3255&#x27;, &#x27;3256&#x27;, &#x27;3257&#x27;, &#x27;3258&#x27;, &#x27;3259&#x27;, &#x27;3260&#x27;, &#x27;3261&#x27;, &#x27;3262&#x27;, &#x27;3263&#x27;, &#x27;3264&#x27;, &#x27;3265&#x27;, &#x27;3266&#x27;, &#x27;3267&#x27;, &#x27;3268&#x27;, &#x27;3269&#x27;, &#x27;3270&#x27;, &#x27;3271&#x27;, &#x27;3272&#x27;, &#x27;3273&#x27;, &#x27;3274&#x27;, &#x27;3275&#x27;, &#x27;3276&#x27;, &#x27;3277&#x27;, &#x27;3278&#x27;, &#x27;3279&#x27;, &#x27;3280&#x27;, &#x27;3281&#x27;, &#x27;3282&#x27;, &#x27;3283&#x27;, &#x27;3284&#x27;, &#x27;3285&#x27;, &#x27;3286&#x27;, &#x27;3287&#x27;, &#x27;3288&#x27;, &#x27;3289&#x27;, &#x27;3290&#x27;, &#x27;3291&#x27;, &#x27;3292&#x27;, &#x27;3293&#x27;, &#x27;3294&#x27;, &#x27;3295&#x27;, &#x27;3296&#x27;, &#x27;3297&#x27;, &#x27;3298&#x27;, &#x27;3299&#x27;, &#x27;3300&#x27;, &#x27;3301&#x27;, &#x27;3302&#x27;, &#x27;3303&#x27;, &#x27;3304&#x27;, &#x27;3305&#x27;, &#x27;3306&#x27;, &#x27;3307&#x27;, &#x27;3308&#x27;, &#x27;3309&#x27;, &#x27;3310&#x27;, &#x27;3311&#x27;, &#x27;3312&#x27;, &#x27;3313&#x27;, &#x27;3314&#x27;, &#x27;3315&#x27;, &#x27;3316&#x27;, &#x27;3317&#x27;, &#x27;3318&#x27;, &#x27;3319&#x27;, &#x27;3320&#x27;, &#x27;3321&#x27;, &#x27;3322&#x27;, &#x27;3323&#x27;, &#x27;3324&#x27;, &#x27;3325&#x27;, &#x27;3326&#x27;, &#x27;3327&#x27;, &#x27;3328&#x27;, &#x27;3329&#x27;, &#x27;3330&#x27;, &#x27;3331&#x27;, &#x27;3332&#x27;, &#x27;3333&#x27;, &#x27;3334&#x27;, &#x27;3335&#x27;, &#x27;3336&#x27;, &#x27;3337&#x27;, &#x27;3338&#x27;, &#x27;3339&#x27;, &#x27;3340&#x27;, &#x27;3341&#x27;, &#x27;3342&#x27;, &#x27;3343&#x27;, &#x27;3344&#x27;, &#x27;3345&#x27;, &#x27;3346&#x27;, &#x27;3347&#x27;, &#x27;3348&#x27;, &#x27;3349&#x27;, &#x27;3350&#x27;, &#x27;3351&#x27;, &#x27;3352&#x27;, &#x27;3353&#x27;, &#x27;3354&#x27;, &#x27;3355&#x27;, &#x27;3356&#x27;, &#x27;3357&#x27;, &#x27;3358&#x27;, &#x27;3359&#x27;, &#x27;3360&#x27;, &#x27;3361&#x27;, &#x27;3362&#x27;, &#x27;3363&#x27;, &#x27;3364&#x27;, &#x27;3365&#x27;, &#x27;3366&#x27;, &#x27;3367&#x27;, &#x27;3368&#x27;, &#x27;3369&#x27;, &#x27;3370&#x27;, &#x27;3371&#x27;, &#x27;3372&#x27;, &#x27;3373&#x27;, &#x27;3374&#x27;, &#x27;3375&#x27;, &#x27;3376&#x27;, &#x27;3377&#x27;, &#x27;3378&#x27;, &#x27;3379&#x27;, &#x27;3380&#x27;, &#x27;3381&#x27;, &#x27;3382&#x27;, &#x27;3383&#x27;, &#x27;3384&#x27;, &#x27;3385&#x27;, &#x27;3386&#x27;, &#x27;3387&#x27;, &#x27;3388&#x27;, &#x27;3389&#x27;, &#x27;3390&#x27;, &#x27;3391&#x27;, &#x27;3392&#x27;, &#x27;3393&#x27;, &#x27;3394&#x27;, &#x27;3395&#x27;, &#x27;3396&#x27;, &#x27;3397&#x27;, &#x27;3398&#x27;, &#x27;3399&#x27;, &#x27;3400&#x27;, &#x27;3401&#x27;, &#x27;3402&#x27;, &#x27;3403&#x27;, &#x27;3404&#x27;, &#x27;3405&#x27;, &#x27;3406&#x27;, &#x27;3407&#x27;, &#x27;3408&#x27;, &#x27;3409&#x27;, &#x27;3410&#x27;, &#x27;3411&#x27;, &#x27;3412&#x27;, &#x27;3413&#x27;, &#x27;3414&#x27;, &#x27;3415&#x27;, &#x27;3416&#x27;, &#x27;3417&#x27;, &#x27;3418&#x27;, &#x27;3419&#x27;, &#x27;3420&#x27;, &#x27;3421&#x27;, &#x27;3422&#x27;, &#x27;3423&#x27;, &#x27;3424&#x27;, &#x27;3425&#x27;, &#x27;3426&#x27;, &#x27;3427&#x27;, &#x27;3428&#x27;, &#x27;3429&#x27;, &#x27;3430&#x27;, &#x27;3431&#x27;, &#x27;3432&#x27;, &#x27;3433&#x27;, &#x27;3434&#x27;, &#x27;3435&#x27;, &#x27;3436&#x27;, &#x27;3437&#x27;, &#x27;3438&#x27;, &#x27;3439&#x27;, &#x27;3440&#x27;, &#x27;3441&#x27;, &#x27;3442&#x27;, &#x27;3443&#x27;, &#x27;3444&#x27;, &#x27;3445&#x27;, &#x27;3446&#x27;, &#x27;3447&#x27;, &#x27;3448&#x27;, &#x27;3449&#x27;, &#x27;3450&#x27;, &#x27;3451&#x27;, &#x27;3452&#x27;, &#x27;3453&#x27;, &#x27;3454&#x27;, &#x27;3455&#x27;, &#x27;3456&#x27;, &#x27;3457&#x27;, &#x27;3458&#x27;, &#x27;3459&#x27;, &#x27;3460&#x27;, &#x27;3461&#x27;, &#x27;3462&#x27;, &#x27;3463&#x27;, &#x27;3464&#x27;, &#x27;3465&#x27;, &#x27;3466&#x27;, &#x27;3467&#x27;, &#x27;3468&#x27;, &#x27;3469&#x27;, &#x27;3470&#x27;, &#x27;3471&#x27;, &#x27;3472&#x27;, &#x27;3473&#x27;, &#x27;3474&#x27;, &#x27;3475&#x27;, &#x27;3476&#x27;, &#x27;3477&#x27;, &#x27;3478&#x27;, &#x27;3479&#x27;, &#x27;3480&#x27;, &#x27;3481&#x27;, &#x27;3482&#x27;, &#x27;3483&#x27;, &#x27;3484&#x27;, &#x27;3485&#x27;, &#x27;3486&#x27;, &#x27;3487&#x27;, &#x27;3488&#x27;, &#x27;3489&#x27;, &#x27;3490&#x27;, &#x27;3491&#x27;, &#x27;3492&#x27;, &#x27;3493&#x27;, &#x27;3494&#x27;, &#x27;3495&#x27;, &#x27;3496&#x27;, &#x27;3497&#x27;, &#x27;3498&#x27;, &#x27;3499&#x27;, &#x27;3500&#x27;, &#x27;3501&#x27;, &#x27;3502&#x27;, &#x27;3503&#x27;, &#x27;3504&#x27;, &#x27;3505&#x27;, &#x27;3506&#x27;, &#x27;3507&#x27;, &#x27;3508&#x27;, &#x27;3509&#x27;, &#x27;3510&#x27;, &#x27;3511&#x27;, &#x27;3512&#x27;, &#x27;3513&#x27;, &#x27;3514&#x27;, &#x27;3515&#x27;, &#x27;3516&#x27;, &#x27;3517&#x27;, &#x27;3518&#x27;, &#x27;3519&#x27;, &#x27;3520&#x27;, &#x27;3521&#x27;, &#x27;3522&#x27;, &#x27;3523&#x27;, &#x27;3524&#x27;, &#x27;3525&#x27;, &#x27;3526&#x27;, &#x27;3527&#x27;, &#x27;3528&#x27;, &#x27;3529&#x27;, &#x27;3530&#x27;, &#x27;3531&#x27;, &#x27;3532&#x27;, &#x27;3533&#x27;, &#x27;3534&#x27;, &#x27;3535&#x27;, &#x27;3536&#x27;, &#x27;3537&#x27;, &#x27;3538&#x27;, &#x27;3539&#x27;, &#x27;3540&#x27;, &#x27;3541&#x27;, &#x27;3542&#x27;, &#x27;3543&#x27;, &#x27;3544&#x27;, &#x27;3545&#x27;, &#x27;3546&#x27;, &#x27;3547&#x27;, &#x27;3548&#x27;, &#x27;3549&#x27;, &#x27;noun_%&#x27;, &#x27;pronoun_%&#x27;, &#x27;verb_%&#x27;, &#x27;adj_%&#x27;, &#x27;determiner_%&#x27;, &#x27;foreign_%&#x27;, &#x27;profanity&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('standard_scaler',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['statement_length',\n",
       "                                                   'word_count',\n",
       "                                                   'sentence_count',\n",
       "                                                   'unique_words',\n",
       "                                                   'lexical_richness',\n",
       "                                                   'punctuation_count']),\n",
       "                                                 ('one_hot_encoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse=False),\n",
       "                                                  ['emotion'])])),\n",
       "                ('XGBoost',\n",
       "                 XGBClassifier(base_sco...\n",
       "                               feature_types=None, gamma=0, gpu_id=-1,\n",
       "                               grow_policy='depthwise', importance_type=None,\n",
       "                               interaction_constraints='',\n",
       "                               learning_rate=0.300000012, max_bin=256,\n",
       "                               max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "                               max_delta_step=0, max_depth=6, max_leaves=0,\n",
       "                               min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=100,\n",
       "                               n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
       "                               random_state=0, ...))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfXGB_nocv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8114035087719298"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfXGB_nocv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "clfSVM = Pipeline(steps = [('preprocessor', ct), ('SVM', SVC())])\n",
    "#logistic regression\n",
    "clfLOGREG = Pipeline(steps = [('preprocessor', ct), ('Logistic Regression', LogisticRegression())])\n",
    "#XGBoost\n",
    "clfXGB = Pipeline(steps = [('preprocessor', ct), ('XGBoost', XGBClassifier())])\n",
    "#Naive Bayes\n",
    "clfNB = Pipeline(steps = [('preprocessor', ct), ('Naive Bayes', GaussianNB())])\n",
    "#Random forest\n",
    "clfRFC = Pipeline(steps = [('preprocessor', ct), ('RFC', RandomForestClassifier())])\n",
    "#neural netTODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carloalmeda/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1 done\n",
      "model 2 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carloalmeda/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/carloalmeda/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 3 done\n",
      "model 4 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carloalmeda/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/carloalmeda/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 5 done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, f1_score, confusion_matrix\n",
    "from collections import defaultdict\n",
    "models = [clfSVM, clfLOGREG, clfXGB, clfNB, clfRFC]\n",
    "fitted_models = []\n",
    "\n",
    "model_scores=defaultdict(list)\n",
    "\n",
    "for idx, model in enumerate(models):\n",
    "    model.fit(X_train, y_train)\n",
    "    name = list(model.named_steps)[1]\n",
    "    \n",
    "    score = model.score(X_test, y_test)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "    tp = conf_mat[0][0]\n",
    "    tn = conf_mat[1][1]\n",
    "    fp = conf_mat[0][1]\n",
    "    fn = conf_mat[1][0]\n",
    "    precision = tp/(tp+fp)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    model_scores['Model'].append(name)\n",
    "    model_scores['Accuracy'].append(score)\n",
    "    model_scores['MAE'].append(mae)\n",
    "    model_scores['MSE'].append(mse)\n",
    "    model_scores['F1 Score'].append(f1)\n",
    "    model_scores['Confusion Matrix'].append(conf_mat)\n",
    "    model_scores['Precision'].append(precision)\n",
    "\n",
    "    fitted_models.append(model)\n",
    "\n",
    "    \n",
    "\n",
    "    joblib.dump(model, f'{name}Classifier.joblib')\n",
    "    print(f'model {idx+1} done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'Model': ['SVM',\n",
       "              'Logistic Regression',\n",
       "              'XGBoost',\n",
       "              'Naive Bayes',\n",
       "              'RFC'],\n",
       "             'Accuracy': [0.793859649122807,\n",
       "              0.8640350877192983,\n",
       "              0.8114035087719298,\n",
       "              0.7675438596491229,\n",
       "              0.8377192982456141],\n",
       "             'MAE': [0.20614035087719298,\n",
       "              0.13596491228070176,\n",
       "              0.18859649122807018,\n",
       "              0.2324561403508772,\n",
       "              0.16228070175438597],\n",
       "             'MSE': [0.20614035087719298,\n",
       "              0.13596491228070176,\n",
       "              0.18859649122807018,\n",
       "              0.2324561403508772,\n",
       "              0.16228070175438597],\n",
       "             'F1 Score': [0.7982832618025751,\n",
       "              0.8516746411483254,\n",
       "              0.7922705314009661,\n",
       "              0.7763713080168776,\n",
       "              0.8310502283105022],\n",
       "             'Confusion Matrix': [array([[88, 33],\n",
       "                     [14, 93]]),\n",
       "              array([[108,  13],\n",
       "                     [ 18,  89]]),\n",
       "              array([[103,  18],\n",
       "                     [ 25,  82]]),\n",
       "              array([[83, 38],\n",
       "                     [15, 92]]),\n",
       "              array([[100,  21],\n",
       "                     [ 16,  91]])],\n",
       "             'Precision': [0.7272727272727273,\n",
       "              0.8925619834710744,\n",
       "              0.8512396694214877,\n",
       "              0.6859504132231405,\n",
       "              0.8264462809917356]})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score, mae, mse, f1, conf_mat, precision\n",
    "model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.DataFrame(model_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.793860</td>\n",
       "      <td>0.206140</td>\n",
       "      <td>0.206140</td>\n",
       "      <td>0.798283</td>\n",
       "      <td>[[88, 33], [14, 93]]</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.864035</td>\n",
       "      <td>0.135965</td>\n",
       "      <td>0.135965</td>\n",
       "      <td>0.851675</td>\n",
       "      <td>[[108, 13], [18, 89]]</td>\n",
       "      <td>0.892562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.811404</td>\n",
       "      <td>0.188596</td>\n",
       "      <td>0.188596</td>\n",
       "      <td>0.792271</td>\n",
       "      <td>[[103, 18], [25, 82]]</td>\n",
       "      <td>0.851240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.767544</td>\n",
       "      <td>0.232456</td>\n",
       "      <td>0.232456</td>\n",
       "      <td>0.776371</td>\n",
       "      <td>[[83, 38], [15, 92]]</td>\n",
       "      <td>0.685950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RFC</td>\n",
       "      <td>0.837719</td>\n",
       "      <td>0.162281</td>\n",
       "      <td>0.162281</td>\n",
       "      <td>0.831050</td>\n",
       "      <td>[[100, 21], [16, 91]]</td>\n",
       "      <td>0.826446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy       MAE       MSE  F1 Score  \\\n",
       "0                  SVM  0.793860  0.206140  0.206140  0.798283   \n",
       "1  Logistic Regression  0.864035  0.135965  0.135965  0.851675   \n",
       "2              XGBoost  0.811404  0.188596  0.188596  0.792271   \n",
       "3          Naive Bayes  0.767544  0.232456  0.232456  0.776371   \n",
       "4                  RFC  0.837719  0.162281  0.162281  0.831050   \n",
       "\n",
       "        Confusion Matrix  Precision  \n",
       "0   [[88, 33], [14, 93]]   0.727273  \n",
       "1  [[108, 13], [18, 89]]   0.892562  \n",
       "2  [[103, 18], [25, 82]]   0.851240  \n",
       "3   [[83, 38], [15, 92]]   0.685950  \n",
       "4  [[100, 21], [16, 91]]   0.826446  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b6ec5c042ddf83e1a0c3f39fbc3e80edf14e579d2f804f9b839dc9985dcd105"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
